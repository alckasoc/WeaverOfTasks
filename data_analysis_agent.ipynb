{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vuMaLAzX9ggc"
      },
      "source": [
        "# 1. Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "3oSmvB2XMb6x"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import sqlite3\n",
        "import pandas as pd\n",
        "import os\n",
        "import dotenv\n",
        "import json\n",
        "from typing import List\n",
        "\n",
        "from llama_index.experimental.query_engine import PandasQueryEngine\n",
        "from langchain_experimental.agents.agent_toolkits import create_csv_agent, create_pandas_dataframe_agent\n",
        "from langchain_community.llms.openai import OpenAI\n",
        "from pandasai import Agent\n",
        "from pandasai.llm import OpenAI\n",
        "from pandasai import SmartDataframe\n",
        "from langchain_core.messages.human import HumanMessage\n",
        "from langchain_community.chat_models.openai import ChatOpenAI\n",
        "from langchain.agents.agent_types import AgentType\n",
        "\n",
        "dotenv.load_dotenv()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fSuJQNDX-eD4"
      },
      "source": [
        "# 2. Baselines with LangChain"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fH3zCKA2t6vf"
      },
      "source": [
        "## 2.1 Fewshot Examples + ICL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQ_7CCzyjklC",
        "outputId": "77494308-2982-46c3-c34a-8cb28a5ffdd2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\tuvin\\anaconda3\\envs\\taskweaver\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.chat_models.openai.ChatOpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
            "  warn_deprecated(\n"
          ]
        }
      ],
      "source": [
        "llm = ChatOpenAI(model=\"gpt-3.5-turbo\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "jX4jq723qp5h"
      },
      "outputs": [],
      "source": [
        "examples = \"\"\"Task: Plot the monthly average temperature data over a year.\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Example data\n",
        "months = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
        "temperatures = [3, 4, 8, 12, 16, 20, 22, 21, 18, 13, 8, 4]\n",
        "\n",
        "# Plotting the data\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(months, temperatures, marker='o', linestyle='-', color='b')\n",
        "plt.title('Monthly Average Temperatures')\n",
        "plt.xlabel('Month')\n",
        "plt.ylabel('Temperature (Â°C)')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "Task: Plot the total sales data for different products.\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Example data\n",
        "products = ['Laptop', 'Smartphone', 'Tablet']\n",
        "sales = [150, 200, 100]\n",
        "\n",
        "# Plotting the data\n",
        "plt.figure(figsize=(7, 5))\n",
        "plt.bar(products, sales, color='green')\n",
        "plt.title('Product Sales Comparison')\n",
        "plt.xlabel('Products')\n",
        "plt.ylabel('Total Sales')\n",
        "plt.show()\n",
        "\n",
        "Task: Plot a scatter plot to analyze the relationship between hours studied and exam scores.\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Example data\n",
        "hours_studied = [1, 2, 3, 4, 5, 6, 7, 8]\n",
        "exam_scores = [55, 60, 65, 70, 75, 85, 90, 95]\n",
        "\n",
        "# Plotting the data\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.scatter(hours_studied, exam_scores, color='red')\n",
        "plt.title('Study Time vs. Exam Scores')\n",
        "plt.xlabel('Hours Studied')\n",
        "plt.ylabel('Exam Score')\n",
        "plt.show()\n",
        "\n",
        "Task: Plot a histogram to observe the distribution of daily visitors to a museum over a month.\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Example data\n",
        "visitors = np.random.normal(250, 50, 30)  # Simulating random daily visitor counts\n",
        "\n",
        "# Plotting the data\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.hist(visitors, bins=10, color='purple')\n",
        "plt.title('Daily Visitors Distribution')\n",
        "plt.xlabel('Visitors')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()\"\"\"\n",
        "\n",
        "prompt = \"\"\"Solve a Python data exploration task.\n",
        "\n",
        "Here are some examples:\n",
        "{examples}\n",
        "(END OF EXAMPLES)\n",
        "\n",
        "The following Python data exploration task is on a pandas DataFrame on wildfires. Below are the columns.\n",
        "\n",
        "Fires: Table including wildfire data for the period of 1992-2015 compiled from US federal, state, and local reporting systems.\n",
        "FOD_ID = Global unique identifier.\n",
        "FPA_ID = Unique identifier that contains information necessary to track back to the original record in the source dataset.\n",
        "SOURCE_SYSTEM_TYPE = Type of source database or system that the record was drawn from (federal, nonfederal, or interagency).\n",
        "SOURCE_SYSTEM = Name of or other identifier for source database or system that the record was drawn from. See Table 1 in Short (2014), or \\Supplements\\FPA_FOD_source_list.pdf, for a list of sources and their identifier.\n",
        "NWCG_REPORTING_AGENCY = Active National Wildlife Coordinating Group (NWCG) Unit Identifier for the agency preparing the fire report (BIA = Bureau of Indian Affairs, BLM = Bureau of Land Management, BOR = Bureau of Reclamation, DOD = Department of Defense, DOE = Department of Energy, FS = Forest Service, FWS = Fish and Wildlife Service, IA = Interagency Organization, NPS = National Park Service, ST/C&L = State, County, or Local Organization, and TRIBE = Tribal Organization).\n",
        "NWCG_REPORTING_UNIT_ID = Active NWCG Unit Identifier for the unit preparing the fire report.\n",
        "NWCG_REPORTING_UNIT_NAME = Active NWCG Unit Name for the unit preparing the fire report.\n",
        "SOURCE_REPORTING_UNIT = Code for the agency unit preparing the fire report, based on code/name in the source dataset.\n",
        "SOURCE_REPORTING_UNIT_NAME = Name of reporting agency unit preparing the fire report, based on code/name in the source dataset.\n",
        "LOCAL_FIRE_REPORT_ID = Number or code that uniquely identifies an incident report for a particular reporting unit and a particular calendar year.\n",
        "LOCAL_INCIDENT_ID = Number or code that uniquely identifies an incident for a particular local fire management organization within a particular calendar year.\n",
        "FIRE_CODE = Code used within the interagency wildland fire community to track and compile cost information for emergency fire suppression (https://www.firecode.gov/).\n",
        "FIRE_NAME = Name of the incident, from the fire report (primary) or ICS-209 report (secondary).\n",
        "ICS_209_INCIDENT_NUMBER = Incident (event) identifier, from the ICS-209 report.\n",
        "ICS_209_NAME = Name of the incident, from the ICS-209 report.\n",
        "MTBS_ID = Incident identifier, from the MTBS perimeter dataset.\n",
        "MTBS_FIRE_NAME = Name of the incident, from the MTBS perimeter dataset.\n",
        "COMPLEX_NAME = Name of the complex under which the fire was ultimately managed, when discernible.\n",
        "FIRE_YEAR = Calendar year in which the fire was discovered or confirmed to exist.\n",
        "DISCOVERY_DATE = Date on which the fire was discovered or confirmed to exist.\n",
        "DISCOVERY_DOY = Day of year on which the fire was discovered or confirmed to exist.\n",
        "DISCOVERY_TIME = Time of day that the fire was discovered or confirmed to exist.\n",
        "STAT_CAUSE_CODE = Code for the (statistical) cause of the fire.\n",
        "STAT_CAUSE_DESCR = Description of the (statistical) cause of the fire.\n",
        "CONT_DATE = Date on which the fire was declared contained or otherwise controlled (mm/dd/yyyy where mm=month, dd=day, and yyyy=year).\n",
        "CONT_DOY = Day of year on which the fire was declared contained or otherwise controlled.\n",
        "CONT_TIME = Time of day that the fire was declared contained or otherwise controlled (hhmm where hh=hour, mm=minutes).\n",
        "FIRE_SIZE = Estimate of acres within the final perimeter of the fire.\n",
        "FIRE_SIZE_CLASS = Code for fire size based on the number of acres within the final fire perimeter expenditures (A=greater than 0 but less than or equal to 0.25 acres, B=0.26-9.9 acres, C=10.0-99.9 acres, D=100-299 acres, E=300 to 999 acres, F=1000 to 4999 acres, and G=5000+ acres).\n",
        "LATITUDE = Latitude (NAD83) for point location of the fire (decimal degrees).\n",
        "LONGITUDE = Longitude (NAD83) for point location of the fire (decimal degrees).\n",
        "OWNER_CODE = Code for primary owner or entity responsible for managing the land at the point of origin of the fire at the time of the incident.\n",
        "OWNER_DESCR = Name of primary owner or entity responsible for managing the land at the point of origin of the fire at the time of the incident.\n",
        "STATE = Two-letter alphabetic code for the state in which the fire burned (or originated), based on the nominal designation in the fire report.\n",
        "COUNTY = County, or equivalent, in which the fire burned (or originated), based on nominal designation in the fire report.\n",
        "FIPS_CODE = Three-digit code from the Federal Information Process Standards (FIPS) publication 6-4 for representation of counties and equivalent entities.\n",
        "FIPS_NAME = County name from the FIPS publication 6-4 for representation of counties and equivalent entities.\n",
        "NWCG_UnitIDActive_20170109: Look-up table containing all NWCG identifiers for agency units that were active (i.e., valid) as of 9 January 2017, when the list was downloaded from https://www.nifc.blm.gov/unit_id/Publish.html and used as the source of values available to populate the following fields in the Fires table: NWCG_REPORTING_AGENCY, NWCG_REPORTING_UNIT_ID, and NWCG_REPORTING_UNIT_NAME.\n",
        "UnitId = NWCG Unit ID.\n",
        "GeographicArea = Two-letter code for the geographic area in which the unit is located (NA=National, IN=International, AK=Alaska, CA=California, EA=Eastern Area, GB=Great Basin, NR=Northern Rockies, NW=Northwest, RM=Rocky Mountain, SA=Southern Area, and SW=Southwest).\n",
        "Gacc = Seven or eight-letter code for the Geographic Area Coordination Center in which the unit is located or primarily affiliated with (CAMBCIFC=Canadian Interagency Forest Fire Centre, USAKCC=Alaska Interagency Coordination Center, USCAONCC=Northern California Area Coordination Center, USCAOSCC=Southern California Coordination Center, USCORMCC=Rocky Mountain Area Coordination Center, USGASAC=Southern Area Coordination Center, USIDNIC=National Interagency Coordination Center, USMTNRC=Northern Rockies Coordination Center, USNMSWC=Southwest Area Coordination Center, USORNWC=Northwest Area Coordination Center, USUTGBC=Western Great Basin Coordination Center, USWIEACC=Eastern Area Coordination Center).\n",
        "WildlandRole = Role of the unit within the wildland fire community.\n",
        "UnitType = Type of unit (e.g., federal, state, local).\n",
        "Department = Department (or state/territory) to which the unit belongs (AK=Alaska, AL=Alabama, AR=Arkansas, AZ=Arizona, CA=California, CO=Colorado, CT=Connecticut, DE=Delaware, DHS=Department of Homeland Security, DOC= Department of Commerce, DOD=Department of Defense, DOE=Department of Energy, DOI= Department of Interior, DOL=Department of Labor, FL=Florida, GA=Georgia, IA=Iowa, IA/GC=Non-Departmental Agencies, ID=Idaho, IL=Illinois, IN=Indiana, KS=Kansas, KY=Kentucky, LA=Louisiana, MA=Massachusetts, MD=Maryland, ME=Maine, MI=Michigan, MN=Minnesota, MO=Missouri, MS=Mississippi, MT=Montana, NC=North Carolina, NE=Nebraska, NG=Non-Government, NH=New Hampshire, NJ=New Jersey, NM=New Mexico, NV=Nevada, NY=New York, OH=Ohio, OK=Oklahoma, OR=Oregon, PA=Pennsylvania, PR=Puerto Rico, RI=Rhode Island, SC=South Carolina, SD=South Dakota, ST/L=State or Local Government, TN=Tennessee, Tribe=Tribe, TX=Texas, USDA=Department of Agriculture, UT=Utah, VA=Virginia, VI=U. S. Virgin Islands, VT=Vermont, WA=Washington, WI=Wisconsin, WV=West Virginia, WY=Wyoming).\n",
        "Agency = Agency or bureau to which the unit belongs (AG=Air Guard, ANC=Alaska Native Corporation, BIA=Bureau of Indian Affairs, BLM=Bureau of Land Management, BOEM=Bureau of Ocean Energy Management, BOR=Bureau of Reclamation, BSEE=Bureau of Safety and Environmental Enforcement, C&L=County & Local, CDF=California Department of Forestry & Fire Protection, DC=Department of Corrections, DFE=Division of Forest Environment, DFF=Division of Forestry Fire & State Lands, DFL=Division of Forests and Land, DFR=Division of Forest Resources, DL=Department of Lands, DNR=Department of Natural Resources, DNRC=Department of Natural Resources and Conservation, DNRF=Department of Natural Resources Forest Service, DOA=Department of Agriculture, DOC=Department of Conservation, DOE=Department of Energy, DOF=Department of Forestry, DVF=Division of Forestry, DWF=Division of Wildland Fire, EPA=Environmental Protection Agency, FC=Forestry Commission, FEMA=Federal Emergency Management Agency, FFC=Bureau of Forest Fire Control, FFP=Forest Fire Protection, FFS=Forest Fire Service, FR=Forest Rangers, FS=Forest Service, FWS=Fish & Wildlife Service, HQ=Headquarters, JC=Job Corps, NBC=National Business Center, NG=National Guard, NNSA=National Nuclear Security Administration, NPS=National Park Service, NWS=National Weather Service, OES=Office of Emergency Services, PRI=Private, SF=State Forestry, SFS=State Forest Service, SP=State Parks, TNC=The Nature Conservancy, USA=United States Army, USACE=United States Army Corps of Engineers, USAF=United States Air Force, USGS=United States Geological Survey, USN=United States Navy).\n",
        "Parent = Agency subgroup to which the unit belongs (A concatenation of State and Unit from this report - https://www.nifc.blm.gov/unit_id/publish/UnitIdReport.rtf).\n",
        "Country = Country in which the unit is located (e.g. US = United States).\n",
        "State = Two-letter code for the state in which the unit is located (or primarily affiliated).\n",
        "Code = Unit code (follows state code to create UnitId).\n",
        "Name = Unit name.\n",
        "\n",
        "Below are the datatypes for each column.\n",
        "\n",
        "RangeIndex: 1880465 entries, 0 to 1880464\n",
        "Data columns (total 39 columns):\n",
        " #   Column                      Dtype\n",
        "---  ------                      -----\n",
        " 0   OBJECTID                    int64\n",
        " 1   FOD_ID                      int64\n",
        " 2   FPA_ID                      object\n",
        " 3   SOURCE_SYSTEM_TYPE          object\n",
        " 4   SOURCE_SYSTEM               object\n",
        " 5   NWCG_REPORTING_AGENCY       object\n",
        " 6   NWCG_REPORTING_UNIT_ID      object\n",
        " 7   NWCG_REPORTING_UNIT_NAME    object\n",
        " 8   SOURCE_REPORTING_UNIT       object\n",
        " 9   SOURCE_REPORTING_UNIT_NAME  object\n",
        " 10  LOCAL_FIRE_REPORT_ID        object\n",
        " 11  LOCAL_INCIDENT_ID           object\n",
        " 12  FIRE_CODE                   object\n",
        " 13  FIRE_NAME                   object\n",
        " 14  ICS_209_INCIDENT_NUMBER     object\n",
        " 15  ICS_209_NAME                object\n",
        " 16  MTBS_ID                     object\n",
        " 17  MTBS_FIRE_NAME              object\n",
        " 18  COMPLEX_NAME                object\n",
        " 19  FIRE_YEAR                   int64\n",
        " 20  DISCOVERY_DATE              datetime64[ns]\n",
        " 21  DISCOVERY_DOY               int64\n",
        " 22  DISCOVERY_TIME              float64\n",
        " 23  STAT_CAUSE_CODE             float64\n",
        " 24  STAT_CAUSE_DESCR            object\n",
        " 25  CONT_DATE                   float64\n",
        " 26  CONT_DOY                    float64\n",
        " 27  CONT_TIME                   float64\n",
        " 28  FIRE_SIZE                   float64\n",
        " 29  FIRE_SIZE_CLASS             object\n",
        " 30  LATITUDE                    float64\n",
        " 31  LONGITUDE                   float64\n",
        " 32  OWNER_CODE                  float64\n",
        " 33  OWNER_DESCR                 object\n",
        " 34  STATE                       object\n",
        " 35  COUNTY                      object\n",
        " 36  FIPS_CODE                   float64\n",
        " 37  FIPS_NAME                   object\n",
        " 38  Shape                       object\n",
        "dtypes: datetime64[ns](1), float64(10), int64(4), object(24)\n",
        "\n",
        "Generate Python code to manipulate the dataframe `df` with the above columns and plot the results. Let's think step by step.\n",
        "Question: {question}\n",
        "\n",
        "Code:\n",
        "\n",
        "# Load in the csv.\n",
        "df = pd.read_csv('wildfires_lite.csv')\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Py13i6xeHnFo",
        "outputId": "446890ae-a62e-43ac-fad1-a36e6cf9aae9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\tuvin\\anaconda3\\envs\\taskweaver\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.7 and will be removed in 0.2.0. Use invoke instead.\n",
            "  warn_deprecated(\n"
          ]
        }
      ],
      "source": [
        "question = \"What counties are the most and least fire-prone?\"\n",
        "formatted_prompt = prompt.format(examples=examples, question=question)\n",
        "out = llm(\n",
        "    [\n",
        "        HumanMessage(\n",
        "            content=formatted_prompt,\n",
        "        )\n",
        "    ]\n",
        ").content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JwQVlpzxKSP9",
        "outputId": "6aff18ec-099a-433b-9842-156bf2d1af05"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# Group the dataframe by county and count the number of fires in each county\n",
            "county_fires = df['COUNTY'].value_counts()\n",
            "\n",
            "# Find the county with the most fires\n",
            "most_fire_prone_county = county_fires.idxmax()\n",
            "most_fires = county_fires.max()\n",
            "\n",
            "# Find the county with the least fires\n",
            "least_fire_prone_county = county_fires.idxmin()\n",
            "least_fires = county_fires.min()\n",
            "\n",
            "# Plotting the results\n",
            "plt.figure(figsize=(10, 5))\n",
            "county_fires.plot(kind='bar', color='orange')\n",
            "plt.title('Number of Fires by County')\n",
            "plt.xlabel('County')\n",
            "plt.ylabel('Number of Fires')\n",
            "plt.xticks(rotation=45)\n",
            "plt.show()\n",
            "\n",
            "print(f\"The most fire-prone county is {most_fire_prone_county} with {most_fires} fires.\")\n",
            "print(f\"The least fire-prone county is {least_fire_prone_county} with {least_fires} fires.\")\n"
          ]
        }
      ],
      "source": [
        "print(out)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r5JSicCauARv"
      },
      "source": [
        "## 2.2 `create_csv_agent`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KMxOYqOHuFgB",
        "outputId": "26103bc1-72db-4742-e1fb-27ea10c8e3f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: To determine the most and least fire-prone counties, we need to analyze the frequency of fires in each county.\n",
            "Action: We can use the `value_counts()` function on the 'COUNTY' column of the dataframe to get the count of fires in each county.\n",
            "Action Input: df['COUNTY'].value_counts()\u001b[0mWe can use the `value_counts()` function on the 'COUNTY' column of the dataframe to get the count of fires in each county. is not a valid tool, try one of [python_repl_ast].\u001b[32;1m\u001b[1;3mI should use the python_repl_ast tool to execute the command and get the count of fires in each county.\n",
            "Action: python_repl_ast\n",
            "Action Input: df['COUNTY'].value_counts()\u001b[0m\u001b[36;1m\u001b[1;3m5.0      824\n",
            "3.0      441\n",
            "39.0     369\n",
            "7.0      360\n",
            "17.0     339\n",
            "        ... \n",
            "189.0      1\n",
            "261.0      1\n",
            "119.0      1\n",
            "135.0      1\n",
            "159.0      1\n",
            "Name: COUNTY, Length: 117, dtype: int64\u001b[0m\u001b[32;1m\u001b[1;3mI now know the final answer\n",
            "Final Answer: The most fire-prone county is county 5 with 824 fires, and the least fire-prone counties are counties 189, 261, 119, 135, and 159 with only 1 fire each.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'input': 'What counties are the most and least fire-prone?',\n",
              " 'output': 'The most fire-prone county is county 5 with 824 fires, and the least fire-prone counties are counties 189, 261, 119, 135, and 159 with only 1 fire each.'}"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "agent = create_csv_agent(\n",
        "    ChatOpenAI(temperature=0),\n",
        "    \"data/wildfires_lite.csv\",\n",
        "    verbose=True,\n",
        ")\n",
        "agent.invoke({\"input\": question})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZwsSagPXuHgM"
      },
      "source": [
        "## 2.3 `create_pandas_dataframe_agent`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "UOMoOfFEkJha"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"data/wildfires_lite.csv\")\n",
        "agent = create_pandas_dataframe_agent(ChatOpenAI(temperature=0), df, verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hJbkaYv6lLz9",
        "outputId": "df8269e3-0dda-4f14-bcd7-f047250da036"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: To determine the most and least fire-prone counties, we need to analyze the frequency of fires in each county.\n",
            "Action: We can use the `value_counts()` function on the 'COUNTY' column of the dataframe to get the count of fires in each county.\n",
            "Action Input: df['COUNTY'].value_counts()\u001b[0mWe can use the `value_counts()` function on the 'COUNTY' column of the dataframe to get the count of fires in each county. is not a valid tool, try one of [python_repl_ast].\u001b[32;1m\u001b[1;3mWe can use the Python shell to get the count of fires in each county.\n",
            "Action: python_repl_ast\n",
            "Action Input: df['COUNTY'].value_counts()\u001b[0m\u001b[36;1m\u001b[1;3m5.0      824\n",
            "3.0      441\n",
            "39.0     369\n",
            "7.0      360\n",
            "17.0     339\n",
            "        ... \n",
            "189.0      1\n",
            "261.0      1\n",
            "119.0      1\n",
            "135.0      1\n",
            "159.0      1\n",
            "Name: COUNTY, Length: 117, dtype: int64\u001b[0m"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "An output parsing error occurred. In order to pass this error back to the agent and have it try again, pass `handle_parsing_errors=True` to the AgentExecutor. This is the error: Parsing LLM output produced both a final answer and a parse-able action:: Now that we have the count of fires in each county, we can determine the most and least fire-prone counties based on these counts.\nAction: Calculate the most and least fire-prone counties\nAction Input: Most fire-prone county: 5.0, Least fire-prone county: 189.0\nFinal Answer: The most fire-prone county is 5.0 and the least fire-prone county is 189.0.",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mOutputParserException\u001b[0m                     Traceback (most recent call last)",
            "File \u001b[1;32mc:\\Users\\tuvin\\anaconda3\\envs\\taskweaver\\lib\\site-packages\\langchain\\agents\\agent.py:1166\u001b[0m, in \u001b[0;36mAgentExecutor._iter_next_step\u001b[1;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[0;32m   1165\u001b[0m     \u001b[38;5;66;03m# Call the LLM to see what to do.\u001b[39;00m\n\u001b[1;32m-> 1166\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magent\u001b[38;5;241m.\u001b[39mplan(\n\u001b[0;32m   1167\u001b[0m         intermediate_steps,\n\u001b[0;32m   1168\u001b[0m         callbacks\u001b[38;5;241m=\u001b[39mrun_manager\u001b[38;5;241m.\u001b[39mget_child() \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1169\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs,\n\u001b[0;32m   1170\u001b[0m     )\n\u001b[0;32m   1171\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m OutputParserException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
            "File \u001b[1;32mc:\\Users\\tuvin\\anaconda3\\envs\\taskweaver\\lib\\site-packages\\langchain\\agents\\agent.py:397\u001b[0m, in \u001b[0;36mRunnableAgent.plan\u001b[1;34m(self, intermediate_steps, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    390\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream_runnable:\n\u001b[0;32m    391\u001b[0m     \u001b[38;5;66;03m# Use streaming to make sure that the underlying LLM is invoked in a\u001b[39;00m\n\u001b[0;32m    392\u001b[0m     \u001b[38;5;66;03m# streaming\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    395\u001b[0m     \u001b[38;5;66;03m# Because the response from the plan is not a generator, we need to\u001b[39;00m\n\u001b[0;32m    396\u001b[0m     \u001b[38;5;66;03m# accumulate the output into final output and return that.\u001b[39;00m\n\u001b[1;32m--> 397\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunnable\u001b[38;5;241m.\u001b[39mstream(inputs, config\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m: callbacks}):\n\u001b[0;32m    398\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m final_output \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "File \u001b[1;32mc:\\Users\\tuvin\\anaconda3\\envs\\taskweaver\\lib\\site-packages\\langchain_core\\runnables\\base.py:2875\u001b[0m, in \u001b[0;36mRunnableSequence.stream\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   2869\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstream\u001b[39m(\n\u001b[0;32m   2870\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   2871\u001b[0m     \u001b[38;5;28minput\u001b[39m: Input,\n\u001b[0;32m   2872\u001b[0m     config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   2873\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Optional[Any],\n\u001b[0;32m   2874\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[Output]:\n\u001b[1;32m-> 2875\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(\u001b[38;5;28miter\u001b[39m([\u001b[38;5;28minput\u001b[39m]), config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\tuvin\\anaconda3\\envs\\taskweaver\\lib\\site-packages\\langchain_core\\runnables\\base.py:2862\u001b[0m, in \u001b[0;36mRunnableSequence.transform\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   2856\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtransform\u001b[39m(\n\u001b[0;32m   2857\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   2858\u001b[0m     \u001b[38;5;28minput\u001b[39m: Iterator[Input],\n\u001b[0;32m   2859\u001b[0m     config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   2860\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Optional[Any],\n\u001b[0;32m   2861\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[Output]:\n\u001b[1;32m-> 2862\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transform_stream_with_config(\n\u001b[0;32m   2863\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m   2864\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transform,\n\u001b[0;32m   2865\u001b[0m         patch_config(config, run_name\u001b[38;5;241m=\u001b[39m(config \u001b[38;5;129;01mor\u001b[39;00m {})\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m   2866\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   2867\u001b[0m     )\n",
            "File \u001b[1;32mc:\\Users\\tuvin\\anaconda3\\envs\\taskweaver\\lib\\site-packages\\langchain_core\\runnables\\base.py:1880\u001b[0m, in \u001b[0;36mRunnable._transform_stream_with_config\u001b[1;34m(self, input, transformer, config, run_type, **kwargs)\u001b[0m\n\u001b[0;32m   1879\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m-> 1880\u001b[0m     chunk: Output \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m   1881\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m chunk\n",
            "File \u001b[1;32mc:\\Users\\tuvin\\anaconda3\\envs\\taskweaver\\lib\\site-packages\\langchain_core\\runnables\\base.py:2826\u001b[0m, in \u001b[0;36mRunnableSequence._transform\u001b[1;34m(self, input, run_manager, config)\u001b[0m\n\u001b[0;32m   2818\u001b[0m     final_pipeline \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39mtransform(\n\u001b[0;32m   2819\u001b[0m         final_pipeline,\n\u001b[0;32m   2820\u001b[0m         patch_config(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2823\u001b[0m         ),\n\u001b[0;32m   2824\u001b[0m     )\n\u001b[1;32m-> 2826\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m output \u001b[38;5;129;01min\u001b[39;00m final_pipeline:\n\u001b[0;32m   2827\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m output\n",
            "File \u001b[1;32mc:\\Users\\tuvin\\anaconda3\\envs\\taskweaver\\lib\\site-packages\\langchain_core\\runnables\\base.py:1300\u001b[0m, in \u001b[0;36mRunnable.transform\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   1299\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m got_first_val:\n\u001b[1;32m-> 1300\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream(final, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\tuvin\\anaconda3\\envs\\taskweaver\\lib\\site-packages\\langchain_core\\runnables\\base.py:808\u001b[0m, in \u001b[0;36mRunnable.stream\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    804\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    805\u001b[0m \u001b[38;5;124;03mDefault implementation of stream, which calls invoke.\u001b[39;00m\n\u001b[0;32m    806\u001b[0m \u001b[38;5;124;03mSubclasses should override this method if they support streaming output.\u001b[39;00m\n\u001b[0;32m    807\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 808\u001b[0m \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\tuvin\\anaconda3\\envs\\taskweaver\\lib\\site-packages\\langchain_core\\output_parsers\\base.py:169\u001b[0m, in \u001b[0;36mBaseOutputParser.invoke\u001b[1;34m(self, input, config)\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28minput\u001b[39m, BaseMessage):\n\u001b[1;32m--> 169\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_with_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    170\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minner_input\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_result\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    171\u001b[0m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatGeneration\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minner_input\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    172\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    173\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    174\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    175\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrun_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    176\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "File \u001b[1;32mc:\\Users\\tuvin\\anaconda3\\envs\\taskweaver\\lib\\site-packages\\langchain_core\\runnables\\base.py:1625\u001b[0m, in \u001b[0;36mRunnable._call_with_config\u001b[1;34m(self, func, input, config, run_type, **kwargs)\u001b[0m\n\u001b[0;32m   1622\u001b[0m     context\u001b[38;5;241m.\u001b[39mrun(var_child_runnable_config\u001b[38;5;241m.\u001b[39mset, child_config)\n\u001b[0;32m   1623\u001b[0m     output \u001b[38;5;241m=\u001b[39m cast(\n\u001b[0;32m   1624\u001b[0m         Output,\n\u001b[1;32m-> 1625\u001b[0m         context\u001b[38;5;241m.\u001b[39mrun(\n\u001b[0;32m   1626\u001b[0m             call_func_with_variable_args,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m   1627\u001b[0m             func,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m   1628\u001b[0m             \u001b[38;5;28minput\u001b[39m,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m   1629\u001b[0m             config,\n\u001b[0;32m   1630\u001b[0m             run_manager,\n\u001b[0;32m   1631\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   1632\u001b[0m         ),\n\u001b[0;32m   1633\u001b[0m     )\n\u001b[0;32m   1634\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
            "File \u001b[1;32mc:\\Users\\tuvin\\anaconda3\\envs\\taskweaver\\lib\\site-packages\\langchain_core\\runnables\\config.py:347\u001b[0m, in \u001b[0;36mcall_func_with_variable_args\u001b[1;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    346\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m run_manager\n\u001b[1;32m--> 347\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\tuvin\\anaconda3\\envs\\taskweaver\\lib\\site-packages\\langchain_core\\output_parsers\\base.py:170\u001b[0m, in \u001b[0;36mBaseOutputParser.invoke.<locals>.<lambda>\u001b[1;34m(inner_input)\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28minput\u001b[39m, BaseMessage):\n\u001b[0;32m    169\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_with_config(\n\u001b[1;32m--> 170\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m inner_input: \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_result\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    171\u001b[0m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatGeneration\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minner_input\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    172\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m    173\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m    174\u001b[0m         config,\n\u001b[0;32m    175\u001b[0m         run_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparser\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    176\u001b[0m     )\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "File \u001b[1;32mc:\\Users\\tuvin\\anaconda3\\envs\\taskweaver\\lib\\site-packages\\langchain_core\\output_parsers\\base.py:221\u001b[0m, in \u001b[0;36mBaseOutputParser.parse_result\u001b[1;34m(self, result, partial)\u001b[0m\n\u001b[0;32m    209\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Parse a list of candidate model Generations into a specific format.\u001b[39;00m\n\u001b[0;32m    210\u001b[0m \n\u001b[0;32m    211\u001b[0m \u001b[38;5;124;03mThe return value is parsed from only the first Generation in the result, which\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    219\u001b[0m \u001b[38;5;124;03m    Structured output.\u001b[39;00m\n\u001b[0;32m    220\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 221\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\tuvin\\anaconda3\\envs\\taskweaver\\lib\\site-packages\\langchain\\agents\\output_parsers\\react_single_input.py:59\u001b[0m, in \u001b[0;36mReActSingleInputOutputParser.parse\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m includes_answer:\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m OutputParserException(\n\u001b[0;32m     60\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mFINAL_ANSWER_AND_PARSABLE_ACTION_ERROR_MESSAGE\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     61\u001b[0m     )\n\u001b[0;32m     62\u001b[0m action \u001b[38;5;241m=\u001b[39m action_match\u001b[38;5;241m.\u001b[39mgroup(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mstrip()\n",
            "\u001b[1;31mOutputParserException\u001b[0m: Parsing LLM output produced both a final answer and a parse-able action:: Now that we have the count of fires in each county, we can determine the most and least fire-prone counties based on these counts.\nAction: Calculate the most and least fire-prone counties\nAction Input: Most fire-prone county: 5.0, Least fire-prone county: 189.0\nFinal Answer: The most fire-prone county is 5.0 and the least fire-prone county is 189.0.",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[17], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\tuvin\\anaconda3\\envs\\taskweaver\\lib\\site-packages\\langchain\\chains\\base.py:163\u001b[0m, in \u001b[0;36mChain.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    162\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[1;32m--> 163\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    164\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(outputs)\n\u001b[0;32m    166\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m include_run_info:\n",
            "File \u001b[1;32mc:\\Users\\tuvin\\anaconda3\\envs\\taskweaver\\lib\\site-packages\\langchain\\chains\\base.py:153\u001b[0m, in \u001b[0;36mChain.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    150\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    151\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_inputs(inputs)\n\u001b[0;32m    152\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 153\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    154\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[0;32m    155\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[0;32m    156\u001b[0m     )\n\u001b[0;32m    158\u001b[0m     final_outputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(\n\u001b[0;32m    159\u001b[0m         inputs, outputs, return_only_outputs\n\u001b[0;32m    160\u001b[0m     )\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
            "File \u001b[1;32mc:\\Users\\tuvin\\anaconda3\\envs\\taskweaver\\lib\\site-packages\\langchain\\agents\\agent.py:1432\u001b[0m, in \u001b[0;36mAgentExecutor._call\u001b[1;34m(self, inputs, run_manager)\u001b[0m\n\u001b[0;32m   1430\u001b[0m \u001b[38;5;66;03m# We now enter the agent loop (until it returns something).\u001b[39;00m\n\u001b[0;32m   1431\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_continue(iterations, time_elapsed):\n\u001b[1;32m-> 1432\u001b[0m     next_step_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_take_next_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1433\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname_to_tool_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1434\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolor_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1435\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1436\u001b[0m \u001b[43m        \u001b[49m\u001b[43mintermediate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1437\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1438\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1439\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(next_step_output, AgentFinish):\n\u001b[0;32m   1440\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_return(\n\u001b[0;32m   1441\u001b[0m             next_step_output, intermediate_steps, run_manager\u001b[38;5;241m=\u001b[39mrun_manager\n\u001b[0;32m   1442\u001b[0m         )\n",
            "File \u001b[1;32mc:\\Users\\tuvin\\anaconda3\\envs\\taskweaver\\lib\\site-packages\\langchain\\agents\\agent.py:1138\u001b[0m, in \u001b[0;36mAgentExecutor._take_next_step\u001b[1;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[0;32m   1129\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_take_next_step\u001b[39m(\n\u001b[0;32m   1130\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1131\u001b[0m     name_to_tool_map: Dict[\u001b[38;5;28mstr\u001b[39m, BaseTool],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1135\u001b[0m     run_manager: Optional[CallbackManagerForChainRun] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1136\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[AgentFinish, List[Tuple[AgentAction, \u001b[38;5;28mstr\u001b[39m]]]:\n\u001b[0;32m   1137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_consume_next_step(\n\u001b[1;32m-> 1138\u001b[0m         [\n\u001b[0;32m   1139\u001b[0m             a\n\u001b[0;32m   1140\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter_next_step(\n\u001b[0;32m   1141\u001b[0m                 name_to_tool_map,\n\u001b[0;32m   1142\u001b[0m                 color_mapping,\n\u001b[0;32m   1143\u001b[0m                 inputs,\n\u001b[0;32m   1144\u001b[0m                 intermediate_steps,\n\u001b[0;32m   1145\u001b[0m                 run_manager,\n\u001b[0;32m   1146\u001b[0m             )\n\u001b[0;32m   1147\u001b[0m         ]\n\u001b[0;32m   1148\u001b[0m     )\n",
            "File \u001b[1;32mc:\\Users\\tuvin\\anaconda3\\envs\\taskweaver\\lib\\site-packages\\langchain\\agents\\agent.py:1138\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   1129\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_take_next_step\u001b[39m(\n\u001b[0;32m   1130\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1131\u001b[0m     name_to_tool_map: Dict[\u001b[38;5;28mstr\u001b[39m, BaseTool],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1135\u001b[0m     run_manager: Optional[CallbackManagerForChainRun] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1136\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[AgentFinish, List[Tuple[AgentAction, \u001b[38;5;28mstr\u001b[39m]]]:\n\u001b[0;32m   1137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_consume_next_step(\n\u001b[1;32m-> 1138\u001b[0m         [\n\u001b[0;32m   1139\u001b[0m             a\n\u001b[0;32m   1140\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter_next_step(\n\u001b[0;32m   1141\u001b[0m                 name_to_tool_map,\n\u001b[0;32m   1142\u001b[0m                 color_mapping,\n\u001b[0;32m   1143\u001b[0m                 inputs,\n\u001b[0;32m   1144\u001b[0m                 intermediate_steps,\n\u001b[0;32m   1145\u001b[0m                 run_manager,\n\u001b[0;32m   1146\u001b[0m             )\n\u001b[0;32m   1147\u001b[0m         ]\n\u001b[0;32m   1148\u001b[0m     )\n",
            "File \u001b[1;32mc:\\Users\\tuvin\\anaconda3\\envs\\taskweaver\\lib\\site-packages\\langchain\\agents\\agent.py:1177\u001b[0m, in \u001b[0;36mAgentExecutor._iter_next_step\u001b[1;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[0;32m   1175\u001b[0m     raise_error \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1176\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m raise_error:\n\u001b[1;32m-> 1177\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1178\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn output parsing error occurred. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1179\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn order to pass this error back to the agent and have it try \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1180\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124magain, pass `handle_parsing_errors=True` to the AgentExecutor. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1181\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis is the error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1182\u001b[0m     )\n\u001b[0;32m   1183\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(e)\n\u001b[0;32m   1184\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_parsing_errors, \u001b[38;5;28mbool\u001b[39m):\n",
            "\u001b[1;31mValueError\u001b[0m: An output parsing error occurred. In order to pass this error back to the agent and have it try again, pass `handle_parsing_errors=True` to the AgentExecutor. This is the error: Parsing LLM output produced both a final answer and a parse-able action:: Now that we have the count of fires in each county, we can determine the most and least fire-prone counties based on these counts.\nAction: Calculate the most and least fire-prone counties\nAction Input: Most fire-prone county: 5.0, Least fire-prone county: 189.0\nFinal Answer: The most fire-prone county is 5.0 and the least fire-prone county is 189.0."
          ]
        }
      ],
      "source": [
        "agent.invoke({\"input\": question})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rS0H4IIx617-"
      },
      "source": [
        "# 3. LlamaIndex `PandasQueryEngine`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "0KR-7zcS7B3C"
      },
      "outputs": [],
      "source": [
        "\n",
        "df = pd.read_csv(\"data/wildfires_lite.csv\")\n",
        "query_engine = PandasQueryEngine(df=df)\n",
        "response = query_engine.query(\n",
        "    \"Have wildfires become more or less frequent over time?\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_BMY4aXq7zo6",
        "outputId": "613fe732-34ef-43ba-bded-198c79f808fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2002       1\n",
            "2004      38\n",
            "2005    6856\n",
            "2006    3104\n",
            "2008       1\n",
            "Name: FIRE_YEAR, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(response.response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r1wi-T07vmpn"
      },
      "source": [
        "# 4. PandasAI and SmartDataframe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For this section, we will try out [PandasAI](https://pandas-ai.com/). To get started, create your `PANDASAI_API_KEY` [here](https://pandabi.ai). Optionally, you can also add it to the `.env` as `PANDASAI_API_KEY`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "gy_6o_BpokLy"
      },
      "outputs": [],
      "source": [
        "os.environ[\"PANDASAI_API_KEY\"] = input(\"Enter your PANDASAI_API_KEY: \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "V4ZWWZaUwJ_f"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"data/wildfires_lite.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ive5QsOfyFa3"
      },
      "outputs": [],
      "source": [
        "llm = OpenAI(api_token=os.getenv(\"OPENAI_API_KEY\"))\n",
        "agent = Agent(df, config={\"llm\": llm})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "5NdPaIRnyJay",
        "outputId": "6f7dc955-db04-4644-ab3d-2b90b67f8030"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'The trend of wildfires over time is decreasing.'"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "questions = [\n",
        "    \"What is this dataset about?\",\n",
        "    \"What questions can I ask?\",\n",
        "    \"Have wildfires become more or less frequent over time?\",\n",
        "    \"What counties are the most and least fire-prone?\",\n",
        "    \"Given the size, location and date, can you predict the cause of a fire wildfire?\",\n",
        "]\n",
        "\n",
        "agent.chat(questions[2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "drr6Idhezb7b",
        "outputId": "848b186d-b7e0-4f59-d449-6d48473a7c3a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The trend of wildfires over time is decreasing.\n"
          ]
        }
      ],
      "source": [
        "# You can instantiate a SmartDataframe with a path to a CSV file\n",
        "sdf = SmartDataframe(\"data/wildfires_lite.csv\", config={\"llm\": llm})\n",
        "\n",
        "response = sdf.chat(questions[2])\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K2Uq8R5X4Meu"
      },
      "source": [
        "# Plan-ReAct-Self-Refine (PRSR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aayqBdwz1jrl",
        "outputId": "92b14899-e399-4c4a-c468-9104e1d7e62e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\tuvin\\anaconda3\\envs\\taskweaver\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.chat_models.openai.ChatOpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
            "  warn_deprecated(\n"
          ]
        }
      ],
      "source": [
        "llm = ChatOpenAI()\n",
        "\n",
        "question = \"What counties are the most and least fire-prone?\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "cellView": "form",
        "id": "_DwQZolV_dKd"
      },
      "outputs": [],
      "source": [
        "#@title Context\n",
        "\n",
        "dataframe_context = \"\"\"The following Python data exploration task is on a pandas DataFrame on wildfires. Below are the columns.\n",
        "\n",
        "Fires: Table including wildfire data for the period of 1992-2015 compiled from US federal, state, and local reporting systems.\n",
        "FOD_ID = Global unique identifier.\n",
        "FPA_ID = Unique identifier that contains information necessary to track back to the original record in the source dataset.\n",
        "SOURCE_SYSTEM_TYPE = Type of source database or system that the record was drawn from (federal, nonfederal, or interagency).\n",
        "SOURCE_SYSTEM = Name of or other identifier for source database or system that the record was drawn from. See Table 1 in Short (2014), or \\Supplements\\FPA_FOD_source_list.pdf, for a list of sources and their identifier.\n",
        "NWCG_REPORTING_AGENCY = Active National Wildlife Coordinating Group (NWCG) Unit Identifier for the agency preparing the fire report (BIA = Bureau of Indian Affairs, BLM = Bureau of Land Management, BOR = Bureau of Reclamation, DOD = Department of Defense, DOE = Department of Energy, FS = Forest Service, FWS = Fish and Wildlife Service, IA = Interagency Organization, NPS = National Park Service, ST/C&L = State, County, or Local Organization, and TRIBE = Tribal Organization).\n",
        "NWCG_REPORTING_UNIT_ID = Active NWCG Unit Identifier for the unit preparing the fire report.\n",
        "NWCG_REPORTING_UNIT_NAME = Active NWCG Unit Name for the unit preparing the fire report.\n",
        "SOURCE_REPORTING_UNIT = Code for the agency unit preparing the fire report, based on code/name in the source dataset.\n",
        "SOURCE_REPORTING_UNIT_NAME = Name of reporting agency unit preparing the fire report, based on code/name in the source dataset.\n",
        "LOCAL_FIRE_REPORT_ID = Number or code that uniquely identifies an incident report for a particular reporting unit and a particular calendar year.\n",
        "LOCAL_INCIDENT_ID = Number or code that uniquely identifies an incident for a particular local fire management organization within a particular calendar year.\n",
        "FIRE_CODE = Code used within the interagency wildland fire community to track and compile cost information for emergency fire suppression (https://www.firecode.gov/).\n",
        "FIRE_NAME = Name of the incident, from the fire report (primary) or ICS-209 report (secondary).\n",
        "ICS_209_INCIDENT_NUMBER = Incident (event) identifier, from the ICS-209 report.\n",
        "ICS_209_NAME = Name of the incident, from the ICS-209 report.\n",
        "MTBS_ID = Incident identifier, from the MTBS perimeter dataset.\n",
        "MTBS_FIRE_NAME = Name of the incident, from the MTBS perimeter dataset.\n",
        "COMPLEX_NAME = Name of the complex under which the fire was ultimately managed, when discernible.\n",
        "FIRE_YEAR = Calendar year in which the fire was discovered or confirmed to exist.\n",
        "DISCOVERY_DATE = Date on which the fire was discovered or confirmed to exist.\n",
        "DISCOVERY_DOY = Day of year on which the fire was discovered or confirmed to exist.\n",
        "DISCOVERY_TIME = Time of day that the fire was discovered or confirmed to exist.\n",
        "STAT_CAUSE_CODE = Code for the (statistical) cause of the fire.\n",
        "STAT_CAUSE_DESCR = Description of the (statistical) cause of the fire.\n",
        "CONT_DATE = Date on which the fire was declared contained or otherwise controlled (mm/dd/yyyy where mm=month, dd=day, and yyyy=year).\n",
        "CONT_DOY = Day of year on which the fire was declared contained or otherwise controlled.\n",
        "CONT_TIME = Time of day that the fire was declared contained or otherwise controlled (hhmm where hh=hour, mm=minutes).\n",
        "FIRE_SIZE = Estimate of acres within the final perimeter of the fire.\n",
        "FIRE_SIZE_CLASS = Code for fire size based on the number of acres within the final fire perimeter expenditures (A=greater than 0 but less than or equal to 0.25 acres, B=0.26-9.9 acres, C=10.0-99.9 acres, D=100-299 acres, E=300 to 999 acres, F=1000 to 4999 acres, and G=5000+ acres).\n",
        "LATITUDE = Latitude (NAD83) for point location of the fire (decimal degrees).\n",
        "LONGITUDE = Longitude (NAD83) for point location of the fire (decimal degrees).\n",
        "OWNER_CODE = Code for primary owner or entity responsible for managing the land at the point of origin of the fire at the time of the incident.\n",
        "OWNER_DESCR = Name of primary owner or entity responsible for managing the land at the point of origin of the fire at the time of the incident.\n",
        "STATE = Two-letter alphabetic code for the state in which the fire burned (or originated), based on the nominal designation in the fire report.\n",
        "COUNTY = County, or equivalent, in which the fire burned (or originated), based on nominal designation in the fire report.\n",
        "FIPS_CODE = Three-digit code from the Federal Information Process Standards (FIPS) publication 6-4 for representation of counties and equivalent entities.\n",
        "FIPS_NAME = County name from the FIPS publication 6-4 for representation of counties and equivalent entities.\n",
        "NWCG_UnitIDActive_20170109: Look-up table containing all NWCG identifiers for agency units that were active (i.e., valid) as of 9 January 2017, when the list was downloaded from https://www.nifc.blm.gov/unit_id/Publish.html and used as the source of values available to populate the following fields in the Fires table: NWCG_REPORTING_AGENCY, NWCG_REPORTING_UNIT_ID, and NWCG_REPORTING_UNIT_NAME.\n",
        "UnitId = NWCG Unit ID.\n",
        "GeographicArea = Two-letter code for the geographic area in which the unit is located (NA=National, IN=International, AK=Alaska, CA=California, EA=Eastern Area, GB=Great Basin, NR=Northern Rockies, NW=Northwest, RM=Rocky Mountain, SA=Southern Area, and SW=Southwest).\n",
        "Gacc = Seven or eight-letter code for the Geographic Area Coordination Center in which the unit is located or primarily affiliated with (CAMBCIFC=Canadian Interagency Forest Fire Centre, USAKCC=Alaska Interagency Coordination Center, USCAONCC=Northern California Area Coordination Center, USCAOSCC=Southern California Coordination Center, USCORMCC=Rocky Mountain Area Coordination Center, USGASAC=Southern Area Coordination Center, USIDNIC=National Interagency Coordination Center, USMTNRC=Northern Rockies Coordination Center, USNMSWC=Southwest Area Coordination Center, USORNWC=Northwest Area Coordination Center, USUTGBC=Western Great Basin Coordination Center, USWIEACC=Eastern Area Coordination Center).\n",
        "WildlandRole = Role of the unit within the wildland fire community.\n",
        "UnitType = Type of unit (e.g., federal, state, local).\n",
        "Department = Department (or state/territory) to which the unit belongs (AK=Alaska, AL=Alabama, AR=Arkansas, AZ=Arizona, CA=California, CO=Colorado, CT=Connecticut, DE=Delaware, DHS=Department of Homeland Security, DOC= Department of Commerce, DOD=Department of Defense, DOE=Department of Energy, DOI= Department of Interior, DOL=Department of Labor, FL=Florida, GA=Georgia, IA=Iowa, IA/GC=Non-Departmental Agencies, ID=Idaho, IL=Illinois, IN=Indiana, KS=Kansas, KY=Kentucky, LA=Louisiana, MA=Massachusetts, MD=Maryland, ME=Maine, MI=Michigan, MN=Minnesota, MO=Missouri, MS=Mississippi, MT=Montana, NC=North Carolina, NE=Nebraska, NG=Non-Government, NH=New Hampshire, NJ=New Jersey, NM=New Mexico, NV=Nevada, NY=New York, OH=Ohio, OK=Oklahoma, OR=Oregon, PA=Pennsylvania, PR=Puerto Rico, RI=Rhode Island, SC=South Carolina, SD=South Dakota, ST/L=State or Local Government, TN=Tennessee, Tribe=Tribe, TX=Texas, USDA=Department of Agriculture, UT=Utah, VA=Virginia, VI=U. S. Virgin Islands, VT=Vermont, WA=Washington, WI=Wisconsin, WV=West Virginia, WY=Wyoming).\n",
        "Agency = Agency or bureau to which the unit belongs (AG=Air Guard, ANC=Alaska Native Corporation, BIA=Bureau of Indian Affairs, BLM=Bureau of Land Management, BOEM=Bureau of Ocean Energy Management, BOR=Bureau of Reclamation, BSEE=Bureau of Safety and Environmental Enforcement, C&L=County & Local, CDF=California Department of Forestry & Fire Protection, DC=Department of Corrections, DFE=Division of Forest Environment, DFF=Division of Forestry Fire & State Lands, DFL=Division of Forests and Land, DFR=Division of Forest Resources, DL=Department of Lands, DNR=Department of Natural Resources, DNRC=Department of Natural Resources and Conservation, DNRF=Department of Natural Resources Forest Service, DOA=Department of Agriculture, DOC=Department of Conservation, DOE=Department of Energy, DOF=Department of Forestry, DVF=Division of Forestry, DWF=Division of Wildland Fire, EPA=Environmental Protection Agency, FC=Forestry Commission, FEMA=Federal Emergency Management Agency, FFC=Bureau of Forest Fire Control, FFP=Forest Fire Protection, FFS=Forest Fire Service, FR=Forest Rangers, FS=Forest Service, FWS=Fish & Wildlife Service, HQ=Headquarters, JC=Job Corps, NBC=National Business Center, NG=National Guard, NNSA=National Nuclear Security Administration, NPS=National Park Service, NWS=National Weather Service, OES=Office of Emergency Services, PRI=Private, SF=State Forestry, SFS=State Forest Service, SP=State Parks, TNC=The Nature Conservancy, USA=United States Army, USACE=United States Army Corps of Engineers, USAF=United States Air Force, USGS=United States Geological Survey, USN=United States Navy).\n",
        "Parent = Agency subgroup to which the unit belongs (A concatenation of State and Unit from this report - https://www.nifc.blm.gov/unit_id/publish/UnitIdReport.rtf).\n",
        "Country = Country in which the unit is located (e.g. US = United States).\n",
        "State = Two-letter code for the state in which the unit is located (or primarily affiliated).\n",
        "Code = Unit code (follows state code to create UnitId).\n",
        "Name = Unit name.\n",
        "\n",
        "Below are the datatypes for each column.\n",
        "\n",
        "RangeIndex: 1880465 entries, 0 to 1880464\n",
        "Data columns (total 39 columns):\n",
        " #   Column                      Dtype\n",
        "---  ------                      -----\n",
        " 0   OBJECTID                    int64\n",
        " 1   FOD_ID                      int64\n",
        " 2   FPA_ID                      object\n",
        " 3   SOURCE_SYSTEM_TYPE          object\n",
        " 4   SOURCE_SYSTEM               object\n",
        " 5   NWCG_REPORTING_AGENCY       object\n",
        " 6   NWCG_REPORTING_UNIT_ID      object\n",
        " 7   NWCG_REPORTING_UNIT_NAME    object\n",
        " 8   SOURCE_REPORTING_UNIT       object\n",
        " 9   SOURCE_REPORTING_UNIT_NAME  object\n",
        " 10  LOCAL_FIRE_REPORT_ID        object\n",
        " 11  LOCAL_INCIDENT_ID           object\n",
        " 12  FIRE_CODE                   object\n",
        " 13  FIRE_NAME                   object\n",
        " 14  ICS_209_INCIDENT_NUMBER     object\n",
        " 15  ICS_209_NAME                object\n",
        " 16  MTBS_ID                     object\n",
        " 17  MTBS_FIRE_NAME              object\n",
        " 18  COMPLEX_NAME                object\n",
        " 19  FIRE_YEAR                   int64\n",
        " 20  DISCOVERY_DATE              datetime64[ns]\n",
        " 21  DISCOVERY_DOY               int64\n",
        " 22  DISCOVERY_TIME              float64\n",
        " 23  STAT_CAUSE_CODE             float64\n",
        " 24  STAT_CAUSE_DESCR            object\n",
        " 25  CONT_DATE                   float64\n",
        " 26  CONT_DOY                    float64\n",
        " 27  CONT_TIME                   float64\n",
        " 28  FIRE_SIZE                   float64\n",
        " 29  FIRE_SIZE_CLASS             object\n",
        " 30  LATITUDE                    float64\n",
        " 31  LONGITUDE                   float64\n",
        " 32  OWNER_CODE                  float64\n",
        " 33  OWNER_DESCR                 object\n",
        " 34  STATE                       object\n",
        " 35  COUNTY                      object\n",
        " 36  FIPS_CODE                   float64\n",
        " 37  FIPS_NAME                   object\n",
        " 38  Shape                       object\n",
        "dtypes: datetime64[ns](1), float64(10), int64(4), object(24)\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "cellView": "form",
        "id": "j10BqqXFcpcn"
      },
      "outputs": [],
      "source": [
        "#@title ReAct Prompt\n",
        "\n",
        "react_prompt = \"\"\"Solve a data analysis sub-task on a wildfires pd.DataFrame with interleaving Thought and Action steps.\n",
        "Thoughts reason about the next appropriate step and Action is the code implementation based on the Thoughts separated by \\\\n.\n",
        "\n",
        "## Context:\n",
        "{context}\n",
        "\n",
        "## Rules:\n",
        "- Complete only the current step of the plan shown below.\n",
        "- Do not add ```python ``` when generating code for Action.\n",
        "- You have a maximum of {max_steps} steps.\n",
        "- Action steps only include code.\n",
        "\n",
        "## Plan:\n",
        "{plan}\n",
        "\n",
        "## Code:\n",
        "```python\n",
        "\n",
        "{code}\n",
        "```\n",
        "\n",
        "The current step is: {current_step}. Let's think step by step.\n",
        "\n",
        "Question: {question}{memory}\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "FxLLcvCpyo16"
      },
      "outputs": [],
      "source": [
        "def generate_react(\n",
        "  question: str,\n",
        "  current_step: int,\n",
        "  plan: str,\n",
        "  memory: str = \"\",\n",
        "  code: str = \"\",\n",
        "  max_steps: int = 1,\n",
        ") -> str:\n",
        "  actions_taken = 0\n",
        "  while actions_taken < max_steps:\n",
        "    # Think.\n",
        "    memory += '\\nThought: '\n",
        "    thought_prompt = react_prompt.format(\n",
        "        max_steps=max_steps,\n",
        "        context=dataframe_context,\n",
        "        question=question,\n",
        "        memory=memory,\n",
        "        code=code,\n",
        "        plan=plan,\n",
        "        current_step=current_step\n",
        "    )\n",
        "    # print(\"THOUGHT PROMPT<===============================================>\")\n",
        "    # print(thought_prompt)\n",
        "    # print(\"THOUGHT PROMPT<===============================================>\")\n",
        "    thought = llm(\n",
        "        [\n",
        "            HumanMessage(\n",
        "                content=thought_prompt,\n",
        "            )\n",
        "        ]\n",
        "    ).content.split(\"Action:\")[0]\n",
        "    # print(\"THOUGHT OUT<===============================================>\")\n",
        "    # print(thought)\n",
        "    # print(\"THOUGHT OUT<===============================================>\")\n",
        "    memory += thought\n",
        "\n",
        "    # Act.\n",
        "    memory += '\\nAction: '\n",
        "    action_prompt = react_prompt.format(\n",
        "        max_steps=max_steps,\n",
        "        context=dataframe_context,\n",
        "        question=question,\n",
        "        memory=memory,\n",
        "        code=code,\n",
        "        plan=plan,\n",
        "        current_step=current_step\n",
        "    )\n",
        "    # print(\"ACTION PROMPT<===============================================>\")\n",
        "    # print(action_prompt)\n",
        "    # print(\"ACTION PROMPT<===============================================>\")\n",
        "    action = llm(\n",
        "        [\n",
        "            HumanMessage(\n",
        "                content=action_prompt,\n",
        "            )\n",
        "        ]\n",
        "    ).content\n",
        "    action = \"\\n\" + action.lstrip(\"```python\").rstrip(\"```\").lstrip(\"\").strip() + \"\\n\"\n",
        "    # print(\"ACTION OUT<===============================================>\")\n",
        "    # print(action)\n",
        "    # print(\"ACTION OUT<===============================================>\")\n",
        "    code += action\n",
        "    memory += action\n",
        "\n",
        "    actions_taken += 1\n",
        "\n",
        "  return code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WhxZmzKcWHLE",
        "outputId": "3d4d5612-fa68-425c-a147-f51d419b610f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\tuvin\\anaconda3\\envs\\taskweaver\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.7 and will be removed in 0.2.0. Use invoke instead.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "county_fire_freq = df['COUNTY'].value_counts()\n",
            "\n"
          ]
        }
      ],
      "source": [
        "out = generate_react(question, current_step=0, plan=\"\")  # Testing if it works.\n",
        "print(out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "cellView": "form",
        "id": "QtyGakzEJ0-B"
      },
      "outputs": [],
      "source": [
        "#@title Refinement Prompt\n",
        "\n",
        "refinement_prompt = \"\"\"You have attempted to answer following data analysis question on a wildfire pd.DataFrame.\n",
        "\n",
        "## Context:\n",
        "{context}\n",
        "\n",
        "You will be provided the plan and code.\n",
        "\n",
        "## Plan:\n",
        "{plan}\n",
        "\n",
        "## Code:\n",
        "{code}\n",
        "\n",
        "There is an error in the code above because of lack of understanding of the question. What is the error?\n",
        "To find the error, go through semantically complete blocks of the code, and check if everything looks good.\n",
        "If there is no error, output only '<CORRECT>'\"\"\"\n",
        "\n",
        "\n",
        "feedback_prompt = \"\"\"You will be given a plan and code that answers a question. The code is erroneous and thus the suggested refinement is provided.\n",
        "\n",
        "## Context:\n",
        "{context}\n",
        "\n",
        "Question: {question}\n",
        "\n",
        "## Plan:\n",
        "{plan}\n",
        "\n",
        "## Code:\n",
        "{code}\n",
        "\n",
        "Refinement: {refinement}\n",
        "\n",
        "Update the code with the refinement suggestions and output this new updated code.\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "2ph4umdgOWJQ"
      },
      "outputs": [],
      "source": [
        "def generate_refinement(plan: str, code: str) -> str:\n",
        "    prompt = refinement_prompt.format(\n",
        "        context=dataframe_context,\n",
        "        plan=plan,\n",
        "        code=code\n",
        "    )\n",
        "    refinement = llm([HumanMessage(content=prompt)]).content\n",
        "    return refinement\n",
        "\n",
        "def refine_code(question: str, plan: str, code: str, refinement: str) -> str:\n",
        "    prompt = feedback_prompt.format(\n",
        "        context=dataframe_context,\n",
        "        question=question,\n",
        "        plan=plan,\n",
        "        code=code,\n",
        "        refinement=refinement\n",
        "    )\n",
        "    code = llm([HumanMessage(content=prompt)]).content\n",
        "    return code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "cellView": "form",
        "id": "BsB4b56Ac-Nu"
      },
      "outputs": [],
      "source": [
        "#@title Planner Prompt\n",
        "\n",
        "planner_instruction_prompt = \"\"\"As the Planner, your job is to decompose the user's data analytics question into a sequential list of substeps.\n",
        "These steps should only be in natural language and understood by a Data Analyst/Scientist who can translate this into Python code.\n",
        "\n",
        "{context}\n",
        "\n",
        "The first step should be to import relevant libraries and read the csv file. The .csv file is located at {csv_file_path}.\n",
        "The last step should be to return the answer(s).\n",
        "\n",
        "Question: {question}\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "WtdUYb-XaKgl"
      },
      "outputs": [],
      "source": [
        "def generate_plan(\n",
        "  question: str,\n",
        "  csv_file_path: str\n",
        ") -> List[str]:\n",
        "    prompt = planner_instruction_prompt.format(context=dataframe_context, question=question, csv_file_path=csv_file_path)\n",
        "    plan = llm([HumanMessage(content=prompt)]).content\n",
        "    plan = plan.split(\"\\n\")\n",
        "\n",
        "    return plan"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fFNj_L2nAMgP",
        "outputId": "96883fe2-7a5c-43fb-80f1-08416bb3f7b9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['1. Import the pandas library.',\n",
              " '2. Read the csv file \"wildfires_lite.csv\" into a pandas DataFrame.',\n",
              " '3. Group the data by the \"COUNTY\" column.',\n",
              " '4. Calculate the total number of fires for each county.',\n",
              " '5. Sort the counties based on the total number of fires in descending order to find the most fire-prone counties.',\n",
              " '6. Identify the county(s) with the highest number of fires.',\n",
              " '7. Sort the counties based on the total number of fires in ascending order to find the least fire-prone counties.',\n",
              " '8. Identify the county(s) with the lowest number of fires.',\n",
              " '9. Return the county(s) identified as the most and least fire-prone.']"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "plan = generate_plan(question, \"wildfires_lite.csv\")\n",
        "plan"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "bDXZnNzENkF-"
      },
      "outputs": [],
      "source": [
        "code = \"\"\n",
        "for current_step, step in enumerate(plan, 1):\n",
        "  # Execute ReAct on the current_step.\n",
        "  code = generate_react(step, plan=\"\\n\".join(plan), current_step=current_step, code=code)\n",
        "\n",
        "# Generate refinement at the end of the plan.\n",
        "refinement = generate_refinement(plan, code)\n",
        "\n",
        "# Consolidate the refinement/feedback and code into a final output.\n",
        "code = refine_code(question, plan, code, refinement)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aKqHh7Z7Jn9E",
        "outputId": "f13ec60f-babf-48d2-baf9-b2a810167b74"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "```python\n",
            "import pandas as pd\n",
            "\n",
            "df = pd.read_csv(\"wildfires_lite.csv\")\n",
            "\n",
            "county_grouped = df.groupby(\"COUNTY\")\n",
            "\n",
            "county_fires_count = county_grouped.size()\n",
            "\n",
            "county_fires_count_sorted = county_fires_count.sort_values(ascending=False)\n",
            "\n",
            "most_fire_prone_counties = county_fires_count_sorted.head(1)\n",
            "\n",
            "least_fire_prone_counties = county_fires_count_sorted.sort_values(ascending=True)\n",
            "\n",
            "most_fire_prone_counties_names = most_fire_prone_counties.index.tolist()\n",
            "least_fire_prone_counties_names = least_fire_prone_counties.index.tolist()\n",
            "\n",
            "most_fire_prone_counties_names, least_fire_prone_counties_names\n",
            "```\n"
          ]
        }
      ],
      "source": [
        "print(code)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mCMUsCHeYsng"
      },
      "source": [
        "# TaskWeaver"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "aWlC3c4xh3nM"
      },
      "outputs": [],
      "source": [
        "# Copy the wildfires_lite.csv to the `sample_data` folder.\n",
        "df = pd.read_csv(\"data/wildfires_lite.csv\")\n",
        "df.to_csv(\"TaskWeaver/project/sample_data/wildfires_lite.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append(\"TaskWeaver\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 158,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4wERwoepfc7L",
        "outputId": "7f8c30c4-b025-4190-e97b-953a118ad7c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'id': 'round-20240418-055303-75c97fc5', 'user_query': 'calculate mean value of /project/sample_data/demo_data.csv', 'state': 'finished', 'post_list': [{'id': 'post-20240418-055303-8f49d791', 'message': 'calculate mean value of /project/sample_data/demo_data.csv', 'send_from': 'User', 'send_to': 'Planner', 'attachment_list': []}, {'id': 'post-20240418-055303-fef7b852', 'message': 'Please load the data file [/project/sample_data/demo_data.csv](/project/sample_data/demo_data.csv) and calculate the mean value of the loaded data', 'send_from': 'Planner', 'send_to': 'CodeInterpreter', 'attachment_list': [{'id': 'atta-20240418-055308-ba53250e', 'type': 'init_plan', 'content': '1. Load /project/sample_data/demo_data.csv file\\n2. Calculate the mean value of the loaded data <sequentially depends on 1>\\n3. Report the calculated mean value to the user <interactively depends on 2>', 'extra': None}, {'id': 'atta-20240418-055313-04bd8367', 'type': 'plan', 'content': '1. Load /project/sample_data/demo_data.csv file and calculate the mean value of the loaded data\\n2. Report the calculated mean value to the user', 'extra': None}, {'id': 'atta-20240418-055316-46bbb434', 'type': 'current_plan_step', 'content': '1. Load /project/sample_data/demo_data.csv file and calculate the mean value of the loaded data', 'extra': None}, {'id': 'atta-20240418-055321-297a1ccb', 'type': 'board', 'content': 'I have drawn up a plan: \\n1. Load /project/sample_data/demo_data.csv file and calculate the mean value of the loaded data\\n2. Report the calculated mean value to the user\\n\\nPlease proceed with this step of this plan: Please load the data file [/project/sample_data/demo_data.csv](/project/sample_data/demo_data.csv) and calculate the mean value of the loaded data', 'extra': None}]}, {'id': 'post-20240418-055321-704bd725', 'message': \"The following python code has been executed:\\n```python\\nimport pandas as pd\\n\\n# Load the data from the CSV file\\ndata_file_path = '/project/sample_data/demo_data.csv'\\ndata_df = pd.read_csv(data_file_path)\\n\\n# Calculate the mean value of the loaded data\\nmean_values = data_df.mean()\\nmean_values\\n```\\n\\n\\nThe execution of the generated python code above has failed\\n\\nDuring execution, the following messages were logged:\\nTraceback (most recent call last):\\n\\n  Cell In[1], line 5\\n    data_df = pd.read_csv(data_file_path)\\n\\n  File /usr/local/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1026 in read_csv\\n    return _read(filepath_or_buffer, kwds)\\n\\n  File /usr/local/lib/python3.10/site-packages/pandas/io/parsers/readers.py:620 in _read\\n    parser = TextFileReader(filepath_or_buffer, **kwds)\\n\\n  File /usr/local/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1620 in __init__\\n    self._engine = self._make_engine(f, self.engine)\\n\\n  File /usr/local/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1880 in _make_engine\\n    self.handles = get_handle(\\n\\n  File /usr/local/lib/python3.10/site-packages/pandas/io/common.py:873 in get_handle\\n    handle = open(\\n\\nFileNotFoundError: [Errno 2] No such file or directory: '/project/sample_data/demo_data.csv'\\n\\n\", 'send_from': 'CodeInterpreter', 'send_to': 'CodeInterpreter', 'attachment_list': [{'id': 'atta-20240418-055324-36a5b79a', 'type': 'thought', 'content': 'ProgramApe will generate a code snippet to load the CSV file using pandas, which is a common library for handling data in Python. After loading the data, ProgramApe will calculate the mean value of the numeric columns.', 'extra': None}, {'id': 'atta-20240418-055330-b157cc92', 'type': 'python', 'content': \"import pandas as pd\\n\\n# Load the data from the CSV file\\ndata_file_path = '/project/sample_data/demo_data.csv'\\ndata_df = pd.read_csv(data_file_path)\\n\\n# Calculate the mean value of the loaded data\\nmean_values = data_df.mean()\\nmean_values\", 'extra': None}, {'id': 'atta-20240418-055336-88768e7e', 'type': 'verification', 'content': 'NONE', 'extra': None}, {'id': 'atta-20240418-055336-c235c132', 'type': 'code_error', 'content': 'No code verification is performed.', 'extra': None}, {'id': 'atta-20240418-055343-4581e7da', 'type': 'execution_status', 'content': 'FAILURE', 'extra': None}, {'id': 'atta-20240418-055343-fec9bcdd', 'type': 'execution_result', 'content': \"The execution of the generated python code above has failed\\n\\nDuring execution, the following messages were logged:\\nTraceback (most recent call last):\\n\\n  Cell In[1], line 5\\n    data_df = pd.read_csv(data_file_path)\\n\\n  File /usr/local/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1026 in read_csv\\n    return _read(filepath_or_buffer, kwds)\\n\\n  File /usr/local/lib/python3.10/site-packages/pandas/io/parsers/readers.py:620 in _read\\n    parser = TextFileReader(filepath_or_buffer, **kwds)\\n\\n  File /usr/local/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1620 in __init__\\n    self._engine = self._make_engine(f, self.engine)\\n\\n  File /usr/local/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1880 in _make_engine\\n    self.handles = get_handle(\\n\\n  File /usr/local/lib/python3.10/site-packages/pandas/io/common.py:873 in get_handle\\n    handle = open(\\n\\nFileNotFoundError: [Errno 2] No such file or directory: '/project/sample_data/demo_data.csv'\\n\\n\", 'extra': None}, {'id': 'atta-20240418-055343-9a5f7b70', 'type': 'artifact_paths', 'content': [], 'extra': None}, {'id': 'atta-20240418-055343-8edd29b6', 'type': 'revise_message', 'content': 'The execution of the previous generated code has failed. If you think you can fix the problem by rewriting the code, please generate code and run it again.\\nOtherwise, please explain the problem to me.', 'extra': None}]}, {'id': 'post-20240418-055343-5ff5d198', 'message': \"The file '/project/sample_data/demo_data.csv' could not be found at the specified location. Please ensure that the file path is correct and that the file exists on the file system.\", 'send_from': 'CodeInterpreter', 'send_to': 'Planner', 'attachment_list': [{'id': 'atta-20240418-055346-d7fccedc', 'type': 'thought', 'content': 'The previous attempt to read the file failed because the file was not found at the specified path. This could be due to an incorrect path or the file not being present at the location.', 'extra': None}, {'id': 'atta-20240418-055350-8b418c43', 'type': 'thought', 'content': 'ProgramApe will not attempt to read the file again since the file does not exist at the given path. Instead, ProgramApe will inform the user about the issue.', 'extra': None}, {'id': 'atta-20240418-055353-8f7f959c', 'type': 'text', 'content': \"The file '/project/sample_data/demo_data.csv' could not be found at the specified location. Please ensure that the file path is correct and that the file exists on the file system.\", 'extra': None}, {'id': 'atta-20240418-055356-3522121a', 'type': 'verification', 'content': 'NONE', 'extra': None}, {'id': 'atta-20240418-055356-c25b290b', 'type': 'code_error', 'content': 'No code verification is performed.', 'extra': None}, {'id': 'atta-20240418-055356-10006b51', 'type': 'execution_status', 'content': 'NONE', 'extra': None}, {'id': 'atta-20240418-055356-dd21a9da', 'type': 'execution_result', 'content': 'No code is executed.', 'extra': None}]}, {'id': 'post-20240418-055356-9edf1276', 'message': \"The file path '/project/sample_data/demo_data.csv' could not be found. Could you please verify if the file path is correct or provide the correct file path?\", 'send_from': 'Planner', 'send_to': 'User', 'attachment_list': [{'id': 'atta-20240418-055358-ce3f5acf', 'type': 'init_plan', 'content': '1. Verify the file path with the user\\n2. Load /project/sample_data/demo_data.csv file <interactively depends on 1>\\n3. Calculate the mean value of the loaded data <sequentially depends on 2>\\n4. Report the calculated mean value to the user <interactively depends on 3>', 'extra': None}, {'id': 'atta-20240418-055404-21b4595c', 'type': 'plan', 'content': '1. Verify the file path with the user\\n2. Load the verified file path and calculate the mean value of the loaded data\\n3. Report the calculated mean value to the user', 'extra': None}, {'id': 'atta-20240418-055408-33aea794', 'type': 'current_plan_step', 'content': '1. Verify the file path with the user', 'extra': None}, {'id': 'atta-20240418-055415-2650cd24', 'type': 'board', 'content': \"I have drawn up a plan: \\n1. Verify the file path with the user\\n2. Load the verified file path and calculate the mean value of the loaded data\\n3. Report the calculated mean value to the user\\n\\nPlease proceed with this step of this plan: The file path '/project/sample_data/demo_data.csv' could not be found. Could you please verify if the file path is correct or provide the correct file path?\", 'extra': None}]}]}\n"
          ]
        }
      ],
      "source": [
        "from taskweaver.app.app import TaskWeaverApp\n",
        "\n",
        "# This is the folder that contains the taskweaver_config.json file and not the repo root. Defaults to \"./project/\"\n",
        "app_dir = \"./TaskWeaver/project/\"\n",
        "app = TaskWeaverApp(app_dir=app_dir)\n",
        "session = app.get_session()\n",
        "\n",
        "user_query = \"calculate mean value of ./TaskWeaver/project/sample_data/demo_data.csv\"\n",
        "response_round = session.send_message(user_query)\n",
        "print(response_round.to_dict())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "fSuJQNDX-eD4",
        "fH3zCKA2t6vf",
        "r5JSicCauARv",
        "ZwsSagPXuHgM",
        "rS0H4IIx617-",
        "r1wi-T07vmpn"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
