{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vuMaLAzX9ggc"
      },
      "source": [
        "# 1. Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "3oSmvB2XMb6x"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import sqlite3\n",
        "import pandas as pd\n",
        "import os\n",
        "import dotenv\n",
        "import json\n",
        "from langchain_community.chat_models.openai import ChatOpenAI\n",
        "\n",
        "dotenv.load_dotenv()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "BD-OgvaLvLka"
      },
      "outputs": [],
      "source": [
        "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fSuJQNDX-eD4"
      },
      "source": [
        "# 2. Baselines with LangChain"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fH3zCKA2t6vf"
      },
      "source": [
        "## 2.1 Fewshot Examples + ICL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQ_7CCzyjklC",
        "outputId": "77494308-2982-46c3-c34a-8cb28a5ffdd2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.chat_models.openai.ChatOpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
            "  warn_deprecated(\n"
          ]
        }
      ],
      "source": [
        "llm = ChatOpenAI(model=\"gpt-3.5-turbo\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jX4jq723qp5h"
      },
      "outputs": [],
      "source": [
        "examples = \"\"\"Task: Plot the monthly average temperature data over a year.\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Example data\n",
        "months = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
        "temperatures = [3, 4, 8, 12, 16, 20, 22, 21, 18, 13, 8, 4]\n",
        "\n",
        "# Plotting the data\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(months, temperatures, marker='o', linestyle='-', color='b')\n",
        "plt.title('Monthly Average Temperatures')\n",
        "plt.xlabel('Month')\n",
        "plt.ylabel('Temperature (Â°C)')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "Task: Plot the total sales data for different products.\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Example data\n",
        "products = ['Laptop', 'Smartphone', 'Tablet']\n",
        "sales = [150, 200, 100]\n",
        "\n",
        "# Plotting the data\n",
        "plt.figure(figsize=(7, 5))\n",
        "plt.bar(products, sales, color='green')\n",
        "plt.title('Product Sales Comparison')\n",
        "plt.xlabel('Products')\n",
        "plt.ylabel('Total Sales')\n",
        "plt.show()\n",
        "\n",
        "Task: Plot a scatter plot to analyze the relationship between hours studied and exam scores.\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Example data\n",
        "hours_studied = [1, 2, 3, 4, 5, 6, 7, 8]\n",
        "exam_scores = [55, 60, 65, 70, 75, 85, 90, 95]\n",
        "\n",
        "# Plotting the data\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.scatter(hours_studied, exam_scores, color='red')\n",
        "plt.title('Study Time vs. Exam Scores')\n",
        "plt.xlabel('Hours Studied')\n",
        "plt.ylabel('Exam Score')\n",
        "plt.show()\n",
        "\n",
        "Task: Plot a histogram to observe the distribution of daily visitors to a museum over a month.\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Example data\n",
        "visitors = np.random.normal(250, 50, 30)  # Simulating random daily visitor counts\n",
        "\n",
        "# Plotting the data\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.hist(visitors, bins=10, color='purple')\n",
        "plt.title('Daily Visitors Distribution')\n",
        "plt.xlabel('Visitors')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()\"\"\"\n",
        "\n",
        "prompt = \"\"\"Solve a Python data exploration task.\n",
        "\n",
        "Here are some examples:\n",
        "{examples}\n",
        "(END OF EXAMPLES)\n",
        "\n",
        "The following Python data exploration task is on a pandas DataFrame on wildfires. Below are the columns.\n",
        "\n",
        "Fires: Table including wildfire data for the period of 1992-2015 compiled from US federal, state, and local reporting systems.\n",
        "FOD_ID = Global unique identifier.\n",
        "FPA_ID = Unique identifier that contains information necessary to track back to the original record in the source dataset.\n",
        "SOURCE_SYSTEM_TYPE = Type of source database or system that the record was drawn from (federal, nonfederal, or interagency).\n",
        "SOURCE_SYSTEM = Name of or other identifier for source database or system that the record was drawn from. See Table 1 in Short (2014), or \\Supplements\\FPA_FOD_source_list.pdf, for a list of sources and their identifier.\n",
        "NWCG_REPORTING_AGENCY = Active National Wildlife Coordinating Group (NWCG) Unit Identifier for the agency preparing the fire report (BIA = Bureau of Indian Affairs, BLM = Bureau of Land Management, BOR = Bureau of Reclamation, DOD = Department of Defense, DOE = Department of Energy, FS = Forest Service, FWS = Fish and Wildlife Service, IA = Interagency Organization, NPS = National Park Service, ST/C&L = State, County, or Local Organization, and TRIBE = Tribal Organization).\n",
        "NWCG_REPORTING_UNIT_ID = Active NWCG Unit Identifier for the unit preparing the fire report.\n",
        "NWCG_REPORTING_UNIT_NAME = Active NWCG Unit Name for the unit preparing the fire report.\n",
        "SOURCE_REPORTING_UNIT = Code for the agency unit preparing the fire report, based on code/name in the source dataset.\n",
        "SOURCE_REPORTING_UNIT_NAME = Name of reporting agency unit preparing the fire report, based on code/name in the source dataset.\n",
        "LOCAL_FIRE_REPORT_ID = Number or code that uniquely identifies an incident report for a particular reporting unit and a particular calendar year.\n",
        "LOCAL_INCIDENT_ID = Number or code that uniquely identifies an incident for a particular local fire management organization within a particular calendar year.\n",
        "FIRE_CODE = Code used within the interagency wildland fire community to track and compile cost information for emergency fire suppression (https://www.firecode.gov/).\n",
        "FIRE_NAME = Name of the incident, from the fire report (primary) or ICS-209 report (secondary).\n",
        "ICS_209_INCIDENT_NUMBER = Incident (event) identifier, from the ICS-209 report.\n",
        "ICS_209_NAME = Name of the incident, from the ICS-209 report.\n",
        "MTBS_ID = Incident identifier, from the MTBS perimeter dataset.\n",
        "MTBS_FIRE_NAME = Name of the incident, from the MTBS perimeter dataset.\n",
        "COMPLEX_NAME = Name of the complex under which the fire was ultimately managed, when discernible.\n",
        "FIRE_YEAR = Calendar year in which the fire was discovered or confirmed to exist.\n",
        "DISCOVERY_DATE = Date on which the fire was discovered or confirmed to exist.\n",
        "DISCOVERY_DOY = Day of year on which the fire was discovered or confirmed to exist.\n",
        "DISCOVERY_TIME = Time of day that the fire was discovered or confirmed to exist.\n",
        "STAT_CAUSE_CODE = Code for the (statistical) cause of the fire.\n",
        "STAT_CAUSE_DESCR = Description of the (statistical) cause of the fire.\n",
        "CONT_DATE = Date on which the fire was declared contained or otherwise controlled (mm/dd/yyyy where mm=month, dd=day, and yyyy=year).\n",
        "CONT_DOY = Day of year on which the fire was declared contained or otherwise controlled.\n",
        "CONT_TIME = Time of day that the fire was declared contained or otherwise controlled (hhmm where hh=hour, mm=minutes).\n",
        "FIRE_SIZE = Estimate of acres within the final perimeter of the fire.\n",
        "FIRE_SIZE_CLASS = Code for fire size based on the number of acres within the final fire perimeter expenditures (A=greater than 0 but less than or equal to 0.25 acres, B=0.26-9.9 acres, C=10.0-99.9 acres, D=100-299 acres, E=300 to 999 acres, F=1000 to 4999 acres, and G=5000+ acres).\n",
        "LATITUDE = Latitude (NAD83) for point location of the fire (decimal degrees).\n",
        "LONGITUDE = Longitude (NAD83) for point location of the fire (decimal degrees).\n",
        "OWNER_CODE = Code for primary owner or entity responsible for managing the land at the point of origin of the fire at the time of the incident.\n",
        "OWNER_DESCR = Name of primary owner or entity responsible for managing the land at the point of origin of the fire at the time of the incident.\n",
        "STATE = Two-letter alphabetic code for the state in which the fire burned (or originated), based on the nominal designation in the fire report.\n",
        "COUNTY = County, or equivalent, in which the fire burned (or originated), based on nominal designation in the fire report.\n",
        "FIPS_CODE = Three-digit code from the Federal Information Process Standards (FIPS) publication 6-4 for representation of counties and equivalent entities.\n",
        "FIPS_NAME = County name from the FIPS publication 6-4 for representation of counties and equivalent entities.\n",
        "NWCG_UnitIDActive_20170109: Look-up table containing all NWCG identifiers for agency units that were active (i.e., valid) as of 9 January 2017, when the list was downloaded from https://www.nifc.blm.gov/unit_id/Publish.html and used as the source of values available to populate the following fields in the Fires table: NWCG_REPORTING_AGENCY, NWCG_REPORTING_UNIT_ID, and NWCG_REPORTING_UNIT_NAME.\n",
        "UnitId = NWCG Unit ID.\n",
        "GeographicArea = Two-letter code for the geographic area in which the unit is located (NA=National, IN=International, AK=Alaska, CA=California, EA=Eastern Area, GB=Great Basin, NR=Northern Rockies, NW=Northwest, RM=Rocky Mountain, SA=Southern Area, and SW=Southwest).\n",
        "Gacc = Seven or eight-letter code for the Geographic Area Coordination Center in which the unit is located or primarily affiliated with (CAMBCIFC=Canadian Interagency Forest Fire Centre, USAKCC=Alaska Interagency Coordination Center, USCAONCC=Northern California Area Coordination Center, USCAOSCC=Southern California Coordination Center, USCORMCC=Rocky Mountain Area Coordination Center, USGASAC=Southern Area Coordination Center, USIDNIC=National Interagency Coordination Center, USMTNRC=Northern Rockies Coordination Center, USNMSWC=Southwest Area Coordination Center, USORNWC=Northwest Area Coordination Center, USUTGBC=Western Great Basin Coordination Center, USWIEACC=Eastern Area Coordination Center).\n",
        "WildlandRole = Role of the unit within the wildland fire community.\n",
        "UnitType = Type of unit (e.g., federal, state, local).\n",
        "Department = Department (or state/territory) to which the unit belongs (AK=Alaska, AL=Alabama, AR=Arkansas, AZ=Arizona, CA=California, CO=Colorado, CT=Connecticut, DE=Delaware, DHS=Department of Homeland Security, DOC= Department of Commerce, DOD=Department of Defense, DOE=Department of Energy, DOI= Department of Interior, DOL=Department of Labor, FL=Florida, GA=Georgia, IA=Iowa, IA/GC=Non-Departmental Agencies, ID=Idaho, IL=Illinois, IN=Indiana, KS=Kansas, KY=Kentucky, LA=Louisiana, MA=Massachusetts, MD=Maryland, ME=Maine, MI=Michigan, MN=Minnesota, MO=Missouri, MS=Mississippi, MT=Montana, NC=North Carolina, NE=Nebraska, NG=Non-Government, NH=New Hampshire, NJ=New Jersey, NM=New Mexico, NV=Nevada, NY=New York, OH=Ohio, OK=Oklahoma, OR=Oregon, PA=Pennsylvania, PR=Puerto Rico, RI=Rhode Island, SC=South Carolina, SD=South Dakota, ST/L=State or Local Government, TN=Tennessee, Tribe=Tribe, TX=Texas, USDA=Department of Agriculture, UT=Utah, VA=Virginia, VI=U. S. Virgin Islands, VT=Vermont, WA=Washington, WI=Wisconsin, WV=West Virginia, WY=Wyoming).\n",
        "Agency = Agency or bureau to which the unit belongs (AG=Air Guard, ANC=Alaska Native Corporation, BIA=Bureau of Indian Affairs, BLM=Bureau of Land Management, BOEM=Bureau of Ocean Energy Management, BOR=Bureau of Reclamation, BSEE=Bureau of Safety and Environmental Enforcement, C&L=County & Local, CDF=California Department of Forestry & Fire Protection, DC=Department of Corrections, DFE=Division of Forest Environment, DFF=Division of Forestry Fire & State Lands, DFL=Division of Forests and Land, DFR=Division of Forest Resources, DL=Department of Lands, DNR=Department of Natural Resources, DNRC=Department of Natural Resources and Conservation, DNRF=Department of Natural Resources Forest Service, DOA=Department of Agriculture, DOC=Department of Conservation, DOE=Department of Energy, DOF=Department of Forestry, DVF=Division of Forestry, DWF=Division of Wildland Fire, EPA=Environmental Protection Agency, FC=Forestry Commission, FEMA=Federal Emergency Management Agency, FFC=Bureau of Forest Fire Control, FFP=Forest Fire Protection, FFS=Forest Fire Service, FR=Forest Rangers, FS=Forest Service, FWS=Fish & Wildlife Service, HQ=Headquarters, JC=Job Corps, NBC=National Business Center, NG=National Guard, NNSA=National Nuclear Security Administration, NPS=National Park Service, NWS=National Weather Service, OES=Office of Emergency Services, PRI=Private, SF=State Forestry, SFS=State Forest Service, SP=State Parks, TNC=The Nature Conservancy, USA=United States Army, USACE=United States Army Corps of Engineers, USAF=United States Air Force, USGS=United States Geological Survey, USN=United States Navy).\n",
        "Parent = Agency subgroup to which the unit belongs (A concatenation of State and Unit from this report - https://www.nifc.blm.gov/unit_id/publish/UnitIdReport.rtf).\n",
        "Country = Country in which the unit is located (e.g. US = United States).\n",
        "State = Two-letter code for the state in which the unit is located (or primarily affiliated).\n",
        "Code = Unit code (follows state code to create UnitId).\n",
        "Name = Unit name.\n",
        "\n",
        "Below are the datatypes for each column.\n",
        "\n",
        "RangeIndex: 1880465 entries, 0 to 1880464\n",
        "Data columns (total 39 columns):\n",
        " #   Column                      Dtype\n",
        "---  ------                      -----\n",
        " 0   OBJECTID                    int64\n",
        " 1   FOD_ID                      int64\n",
        " 2   FPA_ID                      object\n",
        " 3   SOURCE_SYSTEM_TYPE          object\n",
        " 4   SOURCE_SYSTEM               object\n",
        " 5   NWCG_REPORTING_AGENCY       object\n",
        " 6   NWCG_REPORTING_UNIT_ID      object\n",
        " 7   NWCG_REPORTING_UNIT_NAME    object\n",
        " 8   SOURCE_REPORTING_UNIT       object\n",
        " 9   SOURCE_REPORTING_UNIT_NAME  object\n",
        " 10  LOCAL_FIRE_REPORT_ID        object\n",
        " 11  LOCAL_INCIDENT_ID           object\n",
        " 12  FIRE_CODE                   object\n",
        " 13  FIRE_NAME                   object\n",
        " 14  ICS_209_INCIDENT_NUMBER     object\n",
        " 15  ICS_209_NAME                object\n",
        " 16  MTBS_ID                     object\n",
        " 17  MTBS_FIRE_NAME              object\n",
        " 18  COMPLEX_NAME                object\n",
        " 19  FIRE_YEAR                   int64\n",
        " 20  DISCOVERY_DATE              datetime64[ns]\n",
        " 21  DISCOVERY_DOY               int64\n",
        " 22  DISCOVERY_TIME              float64\n",
        " 23  STAT_CAUSE_CODE             float64\n",
        " 24  STAT_CAUSE_DESCR            object\n",
        " 25  CONT_DATE                   float64\n",
        " 26  CONT_DOY                    float64\n",
        " 27  CONT_TIME                   float64\n",
        " 28  FIRE_SIZE                   float64\n",
        " 29  FIRE_SIZE_CLASS             object\n",
        " 30  LATITUDE                    float64\n",
        " 31  LONGITUDE                   float64\n",
        " 32  OWNER_CODE                  float64\n",
        " 33  OWNER_DESCR                 object\n",
        " 34  STATE                       object\n",
        " 35  COUNTY                      object\n",
        " 36  FIPS_CODE                   float64\n",
        " 37  FIPS_NAME                   object\n",
        " 38  Shape                       object\n",
        "dtypes: datetime64[ns](1), float64(10), int64(4), object(24)\n",
        "\n",
        "Generate Python code to manipulate the dataframe `df` with the above columns and plot the results. Let's think step by step.\n",
        "Question: {question}\n",
        "\n",
        "Code:\n",
        "\n",
        "# Load in the csv.\n",
        "df = pd.read_csv('wildfires_lite.csv')\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Py13i6xeHnFo",
        "outputId": "446890ae-a62e-43ac-fad1-a36e6cf9aae9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.7 and will be removed in 0.2.0. Use invoke instead.\n",
            "  warn_deprecated(\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.messages.human import HumanMessage\n",
        "\n",
        "question = \"What counties are the most and least fire-prone?\"\n",
        "formatted_prompt = prompt.format(examples=examples, question=question)\n",
        "out = llm(\n",
        "    [\n",
        "        HumanMessage(\n",
        "            content=formatted_prompt,\n",
        "        )\n",
        "    ]\n",
        ").content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JwQVlpzxKSP9",
        "outputId": "6aff18ec-099a-433b-9842-156bf2d1af05"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# Get the count of fires per county\n",
            "county_fires = df['COUNTY'].value_counts()\n",
            "\n",
            "# Get the most and least fire-prone counties\n",
            "most_fire_prone_county = county_fires.idxmax()\n",
            "least_fire_prone_county = county_fires.idxmin()\n",
            "\n",
            "# Plot the results\n",
            "plt.figure(figsize=(10, 6))\n",
            "county_fires.plot(kind='bar', color='orange')\n",
            "plt.title('Number of Fires per County')\n",
            "plt.xlabel('County')\n",
            "plt.ylabel('Number of Fires')\n",
            "plt.show()\n",
            "\n",
            "print(f\"The most fire-prone county is {most_fire_prone_county} with {county_fires.max()} fires.\")\n",
            "print(f\"The least fire-prone county is {least_fire_prone_county} with {county_fires.min()} fires.\")\n"
          ]
        }
      ],
      "source": [
        "print(out)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r5JSicCauARv"
      },
      "source": [
        "## 2.2 `create_csv_agent`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KMxOYqOHuFgB",
        "outputId": "26103bc1-72db-4742-e1fb-27ea10c8e3f8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.llms.openai.OpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAI`.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: I need to group the dataframe by county and then sum the fire size for each county.\n",
            "Action: python_repl_ast\n",
            "Action Input: df.groupby('COUNTY')['FIRE_SIZE'].sum()\u001b[0m\u001b[36;1m\u001b[1;3mCOUNTY\n",
            "1.0        2074.70\n",
            "3.0      127891.72\n",
            "5.0       31405.45\n",
            "6.0          15.69\n",
            "7.0       28916.43\n",
            "           ...    \n",
            "291.0        30.13\n",
            "295.0        14.50\n",
            "311.0        26.20\n",
            "313.0        26.00\n",
            "510.0        13.20\n",
            "Name: FIRE_SIZE, Length: 117, dtype: float64\u001b[0m\u001b[32;1m\u001b[1;3m I need to sort the results in ascending order to find the least fire-prone counties.\n",
            "Action: python_repl_ast\n",
            "Action Input: df.groupby('COUNTY')['FIRE_SIZE'].sum().sort_values()\u001b[0m\u001b[36;1m\u001b[1;3mCOUNTY\n",
            "135.0         0.10\n",
            "95.0          0.20\n",
            "139.0         0.20\n",
            "119.0         0.30\n",
            "280.0         0.85\n",
            "           ...    \n",
            "27.0      69120.27\n",
            "49.0      84560.06\n",
            "3.0      127891.72\n",
            "13.0     185296.00\n",
            "179.0    428138.98\n",
            "Name: FIRE_SIZE, Length: 117, dtype: float64\u001b[0m\u001b[32;1m\u001b[1;3m I need to sort the results in descending order to find the most fire-prone counties.\n",
            "Action: python_repl_ast\n",
            "Action Input: df.groupby('COUNTY')['FIRE_SIZE'].sum().sort_values(ascending=False)\u001b[0m\u001b[36;1m\u001b[1;3mCOUNTY\n",
            "179.0    428138.98\n",
            "13.0     185296.00\n",
            "3.0      127891.72\n",
            "49.0      84560.06\n",
            "27.0      69120.27\n",
            "           ...    \n",
            "280.0         0.85\n",
            "119.0         0.30\n",
            "139.0         0.20\n",
            "95.0          0.20\n",
            "135.0         0.10\n",
            "Name: FIRE_SIZE, Length: 117, dtype: float64\u001b[0m\u001b[32;1m\u001b[1;3m I now know the final answer.\n",
            "Final Answer: The most fire-prone county is 179.0 with a total fire size of 428138.98 and the least fire-prone county is 135.0 with a total fire size of 0.10.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'input': 'What counties are the most and least fire-prone?',\n",
              " 'output': 'The most fire-prone county is 179.0 with a total fire size of 428138.98 and the least fire-prone county is 135.0 with a total fire size of 0.10.'}"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain_experimental.agents.agent_toolkits import create_csv_agent\n",
        "from langchain_community.llms.openai import OpenAI\n",
        "agent = create_csv_agent(\n",
        "    OpenAI(temperature=0),\n",
        "    \"wildfires_lite.csv\",\n",
        "    verbose=True,\n",
        ")\n",
        "agent.invoke({\"input\": question})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZwsSagPXuHgM"
      },
      "source": [
        "## 2.3 `create_pandas_dataframe_agent`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UOMoOfFEkJha"
      },
      "outputs": [],
      "source": [
        "from langchain.agents.agent_types import AgentType\n",
        "from langchain_community.llms.openai import OpenAI\n",
        "from langchain_experimental.agents.agent_toolkits import create_pandas_dataframe_agent\n",
        "\n",
        "agent = create_pandas_dataframe_agent(OpenAI(temperature=0), df, verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hJbkaYv6lLz9",
        "outputId": "df8269e3-0dda-4f14-bcd7-f047250da036"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: I need to group the dataframe by county and then sum the fire size for each county.\n",
            "Action: python_repl_ast\n",
            "Action Input: df.groupby('COUNTY')['FIRE_SIZE'].sum()\u001b[0m\u001b[36;1m\u001b[1;3mCOUNTY\n",
            "001           256551.37\n",
            "003           167013.37\n",
            "005           137398.65\n",
            "006               36.62\n",
            "007           230359.90\n",
            "                ...    \n",
            "walworth           2.03\n",
            "ward               5.25\n",
            "washington        30.12\n",
            "woodford          17.80\n",
            "yankton          115.20\n",
            "Name: FIRE_SIZE, Length: 3455, dtype: float64\u001b[0m\u001b[32;1m\u001b[1;3m Now I need to sort the results in ascending order to find the least fire-prone counties.\n",
            "Action: python_repl_ast\n",
            "Action Input: df.groupby('COUNTY')['FIRE_SIZE'].sum().sort_values()\u001b[0m\u001b[36;1m\u001b[1;3mCOUNTY\n",
            "BonHomme               0.010\n",
            "Door                   0.010\n",
            "Kitsap C               0.010\n",
            "Trego                  0.020\n",
            "jeauld                 0.050\n",
            "                    ...     \n",
            "Lincoln          1647517.164\n",
            "Yukon-Koyukuk    1754427.690\n",
            "Malheur          1886582.750\n",
            "Owyhee           1982103.900\n",
            "Elko             2919892.340\n",
            "Name: FIRE_SIZE, Length: 3455, dtype: float64\u001b[0m\u001b[32;1m\u001b[1;3m Now I need to sort the results in descending order to find the most fire-prone counties.\n",
            "Action: python_repl_ast\n",
            "Action Input: df.groupby('COUNTY')['FIRE_SIZE'].sum().sort_values(ascending=False)\u001b[0m\u001b[36;1m\u001b[1;3mCOUNTY\n",
            "Elko             2919892.340\n",
            "Owyhee           1982103.900\n",
            "Malheur          1886582.750\n",
            "Yukon-Koyukuk    1754427.690\n",
            "Lincoln          1647517.164\n",
            "                    ...     \n",
            "jeauld                 0.050\n",
            "Trego                  0.020\n",
            "BonHomme               0.010\n",
            "Door                   0.010\n",
            "Kitsap C               0.010\n",
            "Name: FIRE_SIZE, Length: 3455, dtype: float64\u001b[0m\u001b[32;1m\u001b[1;3m I now know the final answer.\n",
            "Final Answer: The most fire-prone counties are Elko, Owyhee, Malheur, Yukon-Koyukuk, and Lincoln. The least fire-prone counties are BonHomme, Door, Kitsap C, Trego, and jeauld.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'input': 'What counties are the most and least fire-prone?',\n",
              " 'output': 'The most fire-prone counties are Elko, Owyhee, Malheur, Yukon-Koyukuk, and Lincoln. The least fire-prone counties are BonHomme, Door, Kitsap C, Trego, and jeauld.'}"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "agent.invoke({\"input\": question})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rS0H4IIx617-"
      },
      "source": [
        "# 3. LlamaIndex `PandasQueryEngine`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0KR-7zcS7B3C"
      },
      "outputs": [],
      "source": [
        "from llama_index.core.query_engine import PandasQueryEngine\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_API_KEY\")\n",
        "\n",
        "df = pd.read_csv(\"wildfires_lite.csv\")\n",
        "query_engine = PandasQueryEngine(df=df)\n",
        "response = query_engine.query(\n",
        "    \"Have wildfires become more or less frequent over time?\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_BMY4aXq7zo6",
        "outputId": "613fe732-34ef-43ba-bded-198c79f808fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2002       1\n",
            "2004      38\n",
            "2005    6856\n",
            "2006    3104\n",
            "2008       1\n",
            "Name: FIRE_YEAR, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(response.response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r1wi-T07vmpn"
      },
      "source": [
        "# 4. PandasAI and SmartDataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gy_6o_BpokLy"
      },
      "outputs": [],
      "source": [
        "from pandasai import Agent\n",
        "\n",
        "os.environ[\"PANDASAI_API_KEY\"] = userdata.get(\"PANDASAI_API_KEY\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V4ZWWZaUwJ_f"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"wildfires_lite.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ive5QsOfyFa3"
      },
      "outputs": [],
      "source": [
        "from pandasai.llm import OpenAI\n",
        "\n",
        "llm = OpenAI(api_token=userdata.get(\"OPENAI_API_KEY\"))\n",
        "agent = Agent(df, config={\"llm\": llm})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "5NdPaIRnyJay",
        "outputId": "6f7dc955-db04-4644-ab3d-2b90b67f8030"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Wildfires have become less frequent over time.'"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "questions = [\n",
        "    \"What is this dataset about?\",\n",
        "    \"What questions can I ask?\",\n",
        "    \"Have wildfires become more or less frequent over time?\",\n",
        "    \"What counties are the most and least fire-prone?\",\n",
        "    \"Given the size, location and date, can you predict the cause of a fire wildfire?\",\n",
        "]\n",
        "\n",
        "agent.chat(questions[2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "drr6Idhezb7b",
        "outputId": "848b186d-b7e0-4f59-d449-6d48473a7c3a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:pandasai.helpers.logger:Failed with error: Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandasai/pipelines/chat/code_execution.py\", line 85, in execute\n",
            "    result = self.execute_code(input, code_context)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandasai/pipelines/chat/code_execution.py\", line 170, in execute_code\n",
            "    exec(code, environment)\n",
            "  File \"<string>\", line 3, in <module>\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandas/core/groupby/generic.py\", line 1416, in __getitem__\n",
            "    return super().__getitem__(key)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandas/core/base.py\", line 248, in __getitem__\n",
            "    raise KeyError(f\"Column not found: {key}\")\n",
            "KeyError: 'Column not found: FIRE_ID'\n",
            "\n",
            "WARNING:pandasai.helpers.logger:Failed to execute code retrying with a correction framework [retry number: 1]\n",
            "ERROR:pandasai.helpers.logger:Failed with error: Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandasai/pipelines/chat/code_execution.py\", line 85, in execute\n",
            "    result = self.execute_code(input, code_context)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandasai/pipelines/chat/code_execution.py\", line 170, in execute_code\n",
            "    exec(code, environment)\n",
            "  File \"<string>\", line 3, in <module>\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandas/core/groupby/generic.py\", line 1416, in __getitem__\n",
            "    return super().__getitem__(key)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandas/core/base.py\", line 248, in __getitem__\n",
            "    raise KeyError(f\"Column not found: {key}\")\n",
            "KeyError: 'Column not found: FIRE_ID'\n",
            "\n",
            "WARNING:pandasai.helpers.logger:Failed to execute code retrying with a correction framework [retry number: 2]\n",
            "ERROR:pandasai.helpers.logger:Failed with error: Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandasai/pipelines/chat/code_execution.py\", line 85, in execute\n",
            "    result = self.execute_code(input, code_context)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandasai/pipelines/chat/code_execution.py\", line 170, in execute_code\n",
            "    exec(code, environment)\n",
            "  File \"<string>\", line 3, in <module>\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandas/core/groupby/generic.py\", line 1416, in __getitem__\n",
            "    return super().__getitem__(key)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandas/core/base.py\", line 248, in __getitem__\n",
            "    raise KeyError(f\"Column not found: {key}\")\n",
            "KeyError: 'Column not found: FIRE_ID'\n",
            "\n",
            "WARNING:pandasai.helpers.logger:Failed to execute code retrying with a correction framework [retry number: 3]\n",
            "ERROR:pandasai.helpers.logger:Failed with error: Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandasai/pipelines/chat/code_execution.py\", line 85, in execute\n",
            "    result = self.execute_code(input, code_context)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandasai/pipelines/chat/code_execution.py\", line 170, in execute_code\n",
            "    exec(code, environment)\n",
            "  File \"<string>\", line 3, in <module>\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandas/core/groupby/generic.py\", line 1416, in __getitem__\n",
            "    return super().__getitem__(key)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandas/core/base.py\", line 248, in __getitem__\n",
            "    raise KeyError(f\"Column not found: {key}\")\n",
            "KeyError: 'Column not found: FIRE_ID'\n",
            "\n",
            "ERROR:pandasai.helpers.logger:Pipeline failed on step 6: 'Column not found: FIRE_ID'\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandasai/pipelines/chat/generate_chat_pipeline.py\", line 283, in run\n",
            "    output = (self.code_generation_pipeline | self.code_execution_pipeline).run(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandasai/pipelines/pipeline.py\", line 137, in run\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandasai/pipelines/pipeline.py\", line 101, in run\n",
            "    step_output = logic.execute(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandasai/pipelines/chat/code_execution.py\", line 114, in execute\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandasai/pipelines/chat/code_execution.py\", line 85, in execute\n",
            "    result = self.execute_code(input, code_context)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandasai/pipelines/chat/code_execution.py\", line 170, in execute_code\n",
            "    exec(code, environment)\n",
            "  File \"<string>\", line 3, in <module>\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandas/core/groupby/generic.py\", line 1416, in __getitem__\n",
            "    return super().__getitem__(key)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandas/core/base.py\", line 248, in __getitem__\n",
            "    raise KeyError(f\"Column not found: {key}\")\n",
            "KeyError: 'Column not found: FIRE_ID'\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unfortunately, I was not able to answer your question, because of the following error:\n",
            "\n",
            "'Column not found: FIRE_ID'\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pandasai import SmartDataframe\n",
        "\n",
        "# You can instantiate a SmartDataframe with a path to a CSV file\n",
        "sdf = SmartDataframe(\"wildfires_lite.csv\", config={\"llm\": llm})\n",
        "\n",
        "response = sdf.chat(questions[5])\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K2Uq8R5X4Meu"
      },
      "source": [
        "# Mini TaskWeaver\n",
        "\n",
        "- http://arxiv.org/abs/2311.17541"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aayqBdwz1jrl",
        "outputId": "92b14899-e399-4c4a-c468-9104e1d7e62e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.chat_models.openai.ChatOpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
            "  warn_deprecated(\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.messages.human import HumanMessage\n",
        "from langchain_community.chat_models.openai import ChatOpenAI\n",
        "\n",
        "llm = ChatOpenAI()\n",
        "\n",
        "question = \"What counties are the most and least fire-prone?\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "cellView": "form",
        "id": "_DwQZolV_dKd"
      },
      "outputs": [],
      "source": [
        "#@title Context\n",
        "\n",
        "dataframe_context = \"\"\"The following Python data exploration task is on a pandas DataFrame on wildfires. Below are the columns.\n",
        "\n",
        "Fires: Table including wildfire data for the period of 1992-2015 compiled from US federal, state, and local reporting systems.\n",
        "FOD_ID = Global unique identifier.\n",
        "FPA_ID = Unique identifier that contains information necessary to track back to the original record in the source dataset.\n",
        "SOURCE_SYSTEM_TYPE = Type of source database or system that the record was drawn from (federal, nonfederal, or interagency).\n",
        "SOURCE_SYSTEM = Name of or other identifier for source database or system that the record was drawn from. See Table 1 in Short (2014), or \\Supplements\\FPA_FOD_source_list.pdf, for a list of sources and their identifier.\n",
        "NWCG_REPORTING_AGENCY = Active National Wildlife Coordinating Group (NWCG) Unit Identifier for the agency preparing the fire report (BIA = Bureau of Indian Affairs, BLM = Bureau of Land Management, BOR = Bureau of Reclamation, DOD = Department of Defense, DOE = Department of Energy, FS = Forest Service, FWS = Fish and Wildlife Service, IA = Interagency Organization, NPS = National Park Service, ST/C&L = State, County, or Local Organization, and TRIBE = Tribal Organization).\n",
        "NWCG_REPORTING_UNIT_ID = Active NWCG Unit Identifier for the unit preparing the fire report.\n",
        "NWCG_REPORTING_UNIT_NAME = Active NWCG Unit Name for the unit preparing the fire report.\n",
        "SOURCE_REPORTING_UNIT = Code for the agency unit preparing the fire report, based on code/name in the source dataset.\n",
        "SOURCE_REPORTING_UNIT_NAME = Name of reporting agency unit preparing the fire report, based on code/name in the source dataset.\n",
        "LOCAL_FIRE_REPORT_ID = Number or code that uniquely identifies an incident report for a particular reporting unit and a particular calendar year.\n",
        "LOCAL_INCIDENT_ID = Number or code that uniquely identifies an incident for a particular local fire management organization within a particular calendar year.\n",
        "FIRE_CODE = Code used within the interagency wildland fire community to track and compile cost information for emergency fire suppression (https://www.firecode.gov/).\n",
        "FIRE_NAME = Name of the incident, from the fire report (primary) or ICS-209 report (secondary).\n",
        "ICS_209_INCIDENT_NUMBER = Incident (event) identifier, from the ICS-209 report.\n",
        "ICS_209_NAME = Name of the incident, from the ICS-209 report.\n",
        "MTBS_ID = Incident identifier, from the MTBS perimeter dataset.\n",
        "MTBS_FIRE_NAME = Name of the incident, from the MTBS perimeter dataset.\n",
        "COMPLEX_NAME = Name of the complex under which the fire was ultimately managed, when discernible.\n",
        "FIRE_YEAR = Calendar year in which the fire was discovered or confirmed to exist.\n",
        "DISCOVERY_DATE = Date on which the fire was discovered or confirmed to exist.\n",
        "DISCOVERY_DOY = Day of year on which the fire was discovered or confirmed to exist.\n",
        "DISCOVERY_TIME = Time of day that the fire was discovered or confirmed to exist.\n",
        "STAT_CAUSE_CODE = Code for the (statistical) cause of the fire.\n",
        "STAT_CAUSE_DESCR = Description of the (statistical) cause of the fire.\n",
        "CONT_DATE = Date on which the fire was declared contained or otherwise controlled (mm/dd/yyyy where mm=month, dd=day, and yyyy=year).\n",
        "CONT_DOY = Day of year on which the fire was declared contained or otherwise controlled.\n",
        "CONT_TIME = Time of day that the fire was declared contained or otherwise controlled (hhmm where hh=hour, mm=minutes).\n",
        "FIRE_SIZE = Estimate of acres within the final perimeter of the fire.\n",
        "FIRE_SIZE_CLASS = Code for fire size based on the number of acres within the final fire perimeter expenditures (A=greater than 0 but less than or equal to 0.25 acres, B=0.26-9.9 acres, C=10.0-99.9 acres, D=100-299 acres, E=300 to 999 acres, F=1000 to 4999 acres, and G=5000+ acres).\n",
        "LATITUDE = Latitude (NAD83) for point location of the fire (decimal degrees).\n",
        "LONGITUDE = Longitude (NAD83) for point location of the fire (decimal degrees).\n",
        "OWNER_CODE = Code for primary owner or entity responsible for managing the land at the point of origin of the fire at the time of the incident.\n",
        "OWNER_DESCR = Name of primary owner or entity responsible for managing the land at the point of origin of the fire at the time of the incident.\n",
        "STATE = Two-letter alphabetic code for the state in which the fire burned (or originated), based on the nominal designation in the fire report.\n",
        "COUNTY = County, or equivalent, in which the fire burned (or originated), based on nominal designation in the fire report.\n",
        "FIPS_CODE = Three-digit code from the Federal Information Process Standards (FIPS) publication 6-4 for representation of counties and equivalent entities.\n",
        "FIPS_NAME = County name from the FIPS publication 6-4 for representation of counties and equivalent entities.\n",
        "NWCG_UnitIDActive_20170109: Look-up table containing all NWCG identifiers for agency units that were active (i.e., valid) as of 9 January 2017, when the list was downloaded from https://www.nifc.blm.gov/unit_id/Publish.html and used as the source of values available to populate the following fields in the Fires table: NWCG_REPORTING_AGENCY, NWCG_REPORTING_UNIT_ID, and NWCG_REPORTING_UNIT_NAME.\n",
        "UnitId = NWCG Unit ID.\n",
        "GeographicArea = Two-letter code for the geographic area in which the unit is located (NA=National, IN=International, AK=Alaska, CA=California, EA=Eastern Area, GB=Great Basin, NR=Northern Rockies, NW=Northwest, RM=Rocky Mountain, SA=Southern Area, and SW=Southwest).\n",
        "Gacc = Seven or eight-letter code for the Geographic Area Coordination Center in which the unit is located or primarily affiliated with (CAMBCIFC=Canadian Interagency Forest Fire Centre, USAKCC=Alaska Interagency Coordination Center, USCAONCC=Northern California Area Coordination Center, USCAOSCC=Southern California Coordination Center, USCORMCC=Rocky Mountain Area Coordination Center, USGASAC=Southern Area Coordination Center, USIDNIC=National Interagency Coordination Center, USMTNRC=Northern Rockies Coordination Center, USNMSWC=Southwest Area Coordination Center, USORNWC=Northwest Area Coordination Center, USUTGBC=Western Great Basin Coordination Center, USWIEACC=Eastern Area Coordination Center).\n",
        "WildlandRole = Role of the unit within the wildland fire community.\n",
        "UnitType = Type of unit (e.g., federal, state, local).\n",
        "Department = Department (or state/territory) to which the unit belongs (AK=Alaska, AL=Alabama, AR=Arkansas, AZ=Arizona, CA=California, CO=Colorado, CT=Connecticut, DE=Delaware, DHS=Department of Homeland Security, DOC= Department of Commerce, DOD=Department of Defense, DOE=Department of Energy, DOI= Department of Interior, DOL=Department of Labor, FL=Florida, GA=Georgia, IA=Iowa, IA/GC=Non-Departmental Agencies, ID=Idaho, IL=Illinois, IN=Indiana, KS=Kansas, KY=Kentucky, LA=Louisiana, MA=Massachusetts, MD=Maryland, ME=Maine, MI=Michigan, MN=Minnesota, MO=Missouri, MS=Mississippi, MT=Montana, NC=North Carolina, NE=Nebraska, NG=Non-Government, NH=New Hampshire, NJ=New Jersey, NM=New Mexico, NV=Nevada, NY=New York, OH=Ohio, OK=Oklahoma, OR=Oregon, PA=Pennsylvania, PR=Puerto Rico, RI=Rhode Island, SC=South Carolina, SD=South Dakota, ST/L=State or Local Government, TN=Tennessee, Tribe=Tribe, TX=Texas, USDA=Department of Agriculture, UT=Utah, VA=Virginia, VI=U. S. Virgin Islands, VT=Vermont, WA=Washington, WI=Wisconsin, WV=West Virginia, WY=Wyoming).\n",
        "Agency = Agency or bureau to which the unit belongs (AG=Air Guard, ANC=Alaska Native Corporation, BIA=Bureau of Indian Affairs, BLM=Bureau of Land Management, BOEM=Bureau of Ocean Energy Management, BOR=Bureau of Reclamation, BSEE=Bureau of Safety and Environmental Enforcement, C&L=County & Local, CDF=California Department of Forestry & Fire Protection, DC=Department of Corrections, DFE=Division of Forest Environment, DFF=Division of Forestry Fire & State Lands, DFL=Division of Forests and Land, DFR=Division of Forest Resources, DL=Department of Lands, DNR=Department of Natural Resources, DNRC=Department of Natural Resources and Conservation, DNRF=Department of Natural Resources Forest Service, DOA=Department of Agriculture, DOC=Department of Conservation, DOE=Department of Energy, DOF=Department of Forestry, DVF=Division of Forestry, DWF=Division of Wildland Fire, EPA=Environmental Protection Agency, FC=Forestry Commission, FEMA=Federal Emergency Management Agency, FFC=Bureau of Forest Fire Control, FFP=Forest Fire Protection, FFS=Forest Fire Service, FR=Forest Rangers, FS=Forest Service, FWS=Fish & Wildlife Service, HQ=Headquarters, JC=Job Corps, NBC=National Business Center, NG=National Guard, NNSA=National Nuclear Security Administration, NPS=National Park Service, NWS=National Weather Service, OES=Office of Emergency Services, PRI=Private, SF=State Forestry, SFS=State Forest Service, SP=State Parks, TNC=The Nature Conservancy, USA=United States Army, USACE=United States Army Corps of Engineers, USAF=United States Air Force, USGS=United States Geological Survey, USN=United States Navy).\n",
        "Parent = Agency subgroup to which the unit belongs (A concatenation of State and Unit from this report - https://www.nifc.blm.gov/unit_id/publish/UnitIdReport.rtf).\n",
        "Country = Country in which the unit is located (e.g. US = United States).\n",
        "State = Two-letter code for the state in which the unit is located (or primarily affiliated).\n",
        "Code = Unit code (follows state code to create UnitId).\n",
        "Name = Unit name.\n",
        "\n",
        "Below are the datatypes for each column.\n",
        "\n",
        "RangeIndex: 1880465 entries, 0 to 1880464\n",
        "Data columns (total 39 columns):\n",
        " #   Column                      Dtype\n",
        "---  ------                      -----\n",
        " 0   OBJECTID                    int64\n",
        " 1   FOD_ID                      int64\n",
        " 2   FPA_ID                      object\n",
        " 3   SOURCE_SYSTEM_TYPE          object\n",
        " 4   SOURCE_SYSTEM               object\n",
        " 5   NWCG_REPORTING_AGENCY       object\n",
        " 6   NWCG_REPORTING_UNIT_ID      object\n",
        " 7   NWCG_REPORTING_UNIT_NAME    object\n",
        " 8   SOURCE_REPORTING_UNIT       object\n",
        " 9   SOURCE_REPORTING_UNIT_NAME  object\n",
        " 10  LOCAL_FIRE_REPORT_ID        object\n",
        " 11  LOCAL_INCIDENT_ID           object\n",
        " 12  FIRE_CODE                   object\n",
        " 13  FIRE_NAME                   object\n",
        " 14  ICS_209_INCIDENT_NUMBER     object\n",
        " 15  ICS_209_NAME                object\n",
        " 16  MTBS_ID                     object\n",
        " 17  MTBS_FIRE_NAME              object\n",
        " 18  COMPLEX_NAME                object\n",
        " 19  FIRE_YEAR                   int64\n",
        " 20  DISCOVERY_DATE              datetime64[ns]\n",
        " 21  DISCOVERY_DOY               int64\n",
        " 22  DISCOVERY_TIME              float64\n",
        " 23  STAT_CAUSE_CODE             float64\n",
        " 24  STAT_CAUSE_DESCR            object\n",
        " 25  CONT_DATE                   float64\n",
        " 26  CONT_DOY                    float64\n",
        " 27  CONT_TIME                   float64\n",
        " 28  FIRE_SIZE                   float64\n",
        " 29  FIRE_SIZE_CLASS             object\n",
        " 30  LATITUDE                    float64\n",
        " 31  LONGITUDE                   float64\n",
        " 32  OWNER_CODE                  float64\n",
        " 33  OWNER_DESCR                 object\n",
        " 34  STATE                       object\n",
        " 35  COUNTY                      object\n",
        " 36  FIPS_CODE                   float64\n",
        " 37  FIPS_NAME                   object\n",
        " 38  Shape                       object\n",
        "dtypes: datetime64[ns](1), float64(10), int64(4), object(24)\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "cellView": "form",
        "id": "j10BqqXFcpcn"
      },
      "outputs": [],
      "source": [
        "#@title ReAct Prompt\n",
        "\n",
        "react_prompt = \"\"\"Solve a data analysis sub-task on a wildfires pd.DataFrame with interleaving Thought and Action steps.\n",
        "Thoughts reason about the next appropriate step and Action is the code implementation based on the Thoughts separated by \\\\n.\n",
        "\n",
        "## Context:\n",
        "{context}\n",
        "\n",
        "## Rules:\n",
        "- Complete only the current step of the plan shown below.\n",
        "- Do not add ```python ``` when generating code for Action.\n",
        "- You have a maximum of {max_steps} steps.\n",
        "- Action steps only include code.\n",
        "\n",
        "## Plan:\n",
        "{plan}\n",
        "\n",
        "## Code:\n",
        "```python\n",
        "\n",
        "{code}\n",
        "```\n",
        "\n",
        "The current step is: {current_step}. Let's think step by step.\n",
        "\n",
        "Question: {question}{memory}\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "FxLLcvCpyo16"
      },
      "outputs": [],
      "source": [
        "def generate_react(\n",
        "  question: str,\n",
        "  current_step: int,\n",
        "  plan: str,\n",
        "  memory: str = \"\",\n",
        "  code: str = \"\",\n",
        "  max_steps: int = 1,\n",
        ") -> str:\n",
        "  actions_taken = 0\n",
        "  while actions_taken < max_steps:\n",
        "    # Think.\n",
        "    memory += '\\nThought: '\n",
        "    thought_prompt = react_prompt.format(\n",
        "        max_steps=max_steps,\n",
        "        context=dataframe_context,\n",
        "        question=question,\n",
        "        memory=memory,\n",
        "        code=code,\n",
        "        plan=plan,\n",
        "        current_step=current_step\n",
        "    )\n",
        "    # print(\"THOUGHT PROMPT<===============================================>\")\n",
        "    # print(thought_prompt)\n",
        "    # print(\"THOUGHT PROMPT<===============================================>\")\n",
        "    thought = llm(\n",
        "        [\n",
        "            HumanMessage(\n",
        "                content=thought_prompt,\n",
        "            )\n",
        "        ]\n",
        "    ).content.split(\"Action:\")[0]\n",
        "    # print(\"THOUGHT OUT<===============================================>\")\n",
        "    # print(thought)\n",
        "    # print(\"THOUGHT OUT<===============================================>\")\n",
        "    memory += thought\n",
        "\n",
        "    # Act.\n",
        "    memory += '\\nAction: '\n",
        "    action_prompt = react_prompt.format(\n",
        "        max_steps=max_steps,\n",
        "        context=dataframe_context,\n",
        "        question=question,\n",
        "        memory=memory,\n",
        "        code=code,\n",
        "        plan=plan,\n",
        "        current_step=current_step\n",
        "    )\n",
        "    # print(\"ACTION PROMPT<===============================================>\")\n",
        "    # print(action_prompt)\n",
        "    # print(\"ACTION PROMPT<===============================================>\")\n",
        "    action = llm(\n",
        "        [\n",
        "            HumanMessage(\n",
        "                content=action_prompt,\n",
        "            )\n",
        "        ]\n",
        "    ).content\n",
        "    action = \"\\n\" + action.lstrip(\"```python\").rstrip(\"```\").lstrip(\"\").strip() + \"\\n\"\n",
        "    # print(\"ACTION OUT<===============================================>\")\n",
        "    # print(action)\n",
        "    # print(\"ACTION OUT<===============================================>\")\n",
        "    code += action\n",
        "    memory += action\n",
        "\n",
        "    actions_taken += 1\n",
        "\n",
        "  return code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WhxZmzKcWHLE",
        "outputId": "3d4d5612-fa68-425c-a147-f51d419b610f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.7 and will be removed in 0.2.0. Use invoke instead.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "county_fires_count = df['COUNTY'].value_counts()\n",
            "\n"
          ]
        }
      ],
      "source": [
        "out = generate_react(question, current_step=0, plan=\"\")  # Testing if it works.\n",
        "print(out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "cellView": "form",
        "id": "QtyGakzEJ0-B"
      },
      "outputs": [],
      "source": [
        "#@title Refinement Prompt\n",
        "\n",
        "refinement_prompt = \"\"\"You have attempted to answer following data analysis question on a wildfire pd.DataFrame.\n",
        "\n",
        "## Context:\n",
        "{context}\n",
        "\n",
        "You will be provided the plan and code.\n",
        "\n",
        "## Plan:\n",
        "{plan}\n",
        "\n",
        "## Code:\n",
        "{code}\n",
        "\n",
        "There is an error in the code above because of lack of understanding of the question. What is the error?\n",
        "To find the error, go through semantically complete blocks of the code, and check if everything looks good.\n",
        "If there is no error, output only '<CORRECT>'\"\"\"\n",
        "\n",
        "\n",
        "feedback_prompt = \"\"\"You will be given a plan and code that answers a question. The code is erroneous and thus the suggested refinement is provided.\n",
        "\n",
        "## Context:\n",
        "{context}\n",
        "\n",
        "Question: {question}\n",
        "\n",
        "## Plan:\n",
        "{plan}\n",
        "\n",
        "## Code:\n",
        "{code}\n",
        "\n",
        "Refinement: {refinement}\n",
        "\n",
        "Update the code with the refinement suggestions and output this new updated code.\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "2ph4umdgOWJQ"
      },
      "outputs": [],
      "source": [
        "def generate_refinement(plan: str, code: str) -> str:\n",
        "    prompt = refinement_prompt.format(\n",
        "        context=dataframe_context,\n",
        "        plan=plan,\n",
        "        code=code\n",
        "    )\n",
        "    refinement = llm([HumanMessage(content=prompt)]).content\n",
        "    return refinement\n",
        "\n",
        "def refine_code(question: str, plan: str, code: str, refinement: str) -> str:\n",
        "    prompt = feedback_prompt.format(\n",
        "        context=dataframe_context,\n",
        "        question=question,\n",
        "        plan=plan,\n",
        "        code=code,\n",
        "        refinement=refinement\n",
        "    )\n",
        "    code = llm([HumanMessage(content=prompt)]).content\n",
        "    return code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "cellView": "form",
        "id": "BsB4b56Ac-Nu"
      },
      "outputs": [],
      "source": [
        "#@title Planner Prompt\n",
        "\n",
        "planner_instruction_prompt = \"\"\"As the Planner, your job is to decompose the user's data analytics question into a sequential list of substeps.\n",
        "These steps should only be in natural language and understood by a Data Analyst/Scientist who can translate this into Python code.\n",
        "\n",
        "{context}\n",
        "\n",
        "The first step should be to import relevant libraries and read the csv file. The .csv file is located at {csv_file_path}.\n",
        "The last step should be to return the answer(s).\n",
        "\n",
        "Question: {question}\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "WtdUYb-XaKgl"
      },
      "outputs": [],
      "source": [
        "from typing import List\n",
        "\n",
        "def generate_plan(\n",
        "  question: str,\n",
        "  csv_file_path: str\n",
        ") -> List[str]:\n",
        "    prompt = planner_instruction_prompt.format(context=dataframe_context, question=question, csv_file_path=csv_file_path)\n",
        "    plan = llm([HumanMessage(content=prompt)]).content\n",
        "    plan = plan.split(\"\\n\")\n",
        "\n",
        "    return plan"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fFNj_L2nAMgP",
        "outputId": "96883fe2-7a5c-43fb-80f1-08416bb3f7b9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['1. Import the pandas library.',\n",
              " '2. Read the CSV file \"wildfires_lite.csv\" into a pandas DataFrame.',\n",
              " '3. Group the data by the \"COUNTY\" column to calculate the total number of wildfires per county.',\n",
              " '4. Sort the counties based on the total number of wildfires in descending order to identify the most fire-prone counties.',\n",
              " '5. Identify the county with the highest number of wildfires as the most fire-prone county.',\n",
              " '6. Identify the county with the lowest number of wildfires as the least fire-prone county.',\n",
              " '7. Return the name of the most fire-prone county.',\n",
              " '8. Return the name of the least fire-prone county.']"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "plan = generate_plan(question, \"wildfires_lite.csv\")\n",
        "plan"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "bDXZnNzENkF-"
      },
      "outputs": [],
      "source": [
        "code = \"\"\n",
        "for current_step, step in enumerate(plan, 1):\n",
        "  # Execute ReAct on the current_step.\n",
        "  code = generate_react(step, plan=\"\\n\".join(plan), current_step=current_step, code=code)\n",
        "\n",
        "# Generate refinement at the end of the plan.\n",
        "refinement = generate_refinement(plan, code)\n",
        "\n",
        "# Consolidate the refinement/feedback and code into a final output.\n",
        "code = refine_code(question, plan, code, refinement)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aKqHh7Z7Jn9E",
        "outputId": "f13ec60f-babf-48d2-baf9-b2a810167b74"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "```python\n",
            "import pandas as pd\n",
            "\n",
            "df = pd.read_csv(\"wildfires.csv\")\n",
            "df.head()\n",
            "\n",
            "county_wildfires = df.groupby(\"COUNTY\").size()\n",
            "county_wildfires\n",
            "\n",
            "sorted_counties = county_wildfires.sort_values(ascending=False)\n",
            "sorted_counties\n",
            "\n",
            "max_county = sorted_counties.idxmax()\n",
            "max_county\n",
            "\n",
            "min_county = sorted_counties.idxmin()\n",
            "min_county\n",
            "\n",
            "max_county = sorted_counties.index[0]\n",
            "max_county\n",
            "\n",
            "min_county = sorted_counties.index[-1]\n",
            "min_county\n",
            "```\n"
          ]
        }
      ],
      "source": [
        "print(code)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mCMUsCHeYsng"
      },
      "source": [
        "# TaskWeaver"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "U8CQ9u-IYxqG"
      },
      "outputs": [],
      "source": [
        "#@title Install TaskWeaver\n",
        "\n",
        "!git clone https://github.com/microsoft/TaskWeaver.git\n",
        "!pip install -r TaskWeaver/requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aWlC3c4xh3nM"
      },
      "outputs": [],
      "source": [
        "# Copy the wildfires_lite.csv to the `sample_data` folder.\n",
        "df = pd.read_csv(\"wildfires_lite.csv\")\n",
        "df.to_csv(\"/content/TaskWeaver/project/sample_data/wildfires_lite.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "cellView": "form",
        "id": "9I2WnAzlY4mD"
      },
      "outputs": [],
      "source": [
        "#@title Configure TaskWeaver\n",
        "\n",
        "import json\n",
        "\n",
        "file_path = \"/content/TaskWeaver/project/taskweaver_config.json\"\n",
        "\n",
        "def set_to_local() -> None:\n",
        "    # Open the existing JSON file for reading.\n",
        "    with open(file_path, 'r') as file:\n",
        "        data = json.load(file)\n",
        "\n",
        "    # Change from Docker to local.\n",
        "    data['execution_service.kernel_mode'] = \"local\"\n",
        "\n",
        "    # Open the JSON file for writing to save the updates.\n",
        "    with open(file_path, 'w') as file:\n",
        "        json.dump(data, file, indent=4)\n",
        "\n",
        "def update_api_key(new_api_key: str, file_path: str) -> None:\n",
        "    # Open the existing JSON file for reading.\n",
        "    with open(file_path, 'r') as file:\n",
        "        data = json.load(file)\n",
        "\n",
        "    # Update the API key.\n",
        "    data['llm.api_key'] = new_api_key\n",
        "\n",
        "    # Open the JSON file for writing to save the updates.\n",
        "    with open(file_path, 'w') as file:\n",
        "        json.dump(data, file, indent=4)\n",
        "\n",
        "set_to_local()\n",
        "update_api_key(userdata.get(\"OPENAI_API_KEY\"), file_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Zx0G4Wjf13D",
        "outputId": "95ecb7b7-d4a5-4f20-ffad-8763a1b6626d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/TaskWeaver\n",
            "auto_eval\t    docker\tproject\t\t  scripts      SUPPORT.md  tracing\n",
            "CODE_OF_CONDUCT.md  LICENSE\tREADME.md\t  SECURITY.md  taskweaver  version.json\n",
            "CONTRIBUTING.md     playground\trequirements.txt  setup.py     tests\t   website\n"
          ]
        }
      ],
      "source": [
        "# Change directory into the main folder.\n",
        "%cd /content/TaskWeaver/\n",
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4wERwoepfc7L",
        "outputId": "7f8c30c4-b025-4190-e97b-953a118ad7c6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:taskweaver.logging:Session 20240418-003942-d935226d is initialized\n",
            "INFO:taskweaver.logging:CodeGenerator initialized successfully\n",
            "INFO:taskweaver.logging:CodeInterpreter initialized successfully.\n",
            "INFO:taskweaver.logging:Planner initialized successfully\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TaskWeaver is running in the `local` mode. This implies that the code execution service will run on the same machine as the TaskWeaver server. For better security, it is recommended to run the code execution service in the `container` mode. More information can be found in the documentation (https://microsoft.github.io/TaskWeaver/docs/code_execution/).\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:taskweaver.logging:LLM output: {\"response\": [{\"type\": \"init_plan\", \"content\": \"1. Load demo_data.csv and show me the top 5 rows to understand the data schema\\n2. Confirm the column to calculate the mean value <sequentially depends on 1>\\n3. Calculate the mean value of the specified column <interactively depends on 2>\\n4. Report the calculated mean value to the user <interactively depends on 3>\"}, {\"type\": \"plan\", \"content\": \"1. Load demo_data.csv and show me the top 5 rows to understand the data schema and confirm the column to calculate the mean value\\n2. Calculate the mean value of the specified column\\n3. Report the calculated mean value to the user\"}, {\"type\": \"current_plan_step\", \"content\": \"1. Load demo_data.csv and show me the top 5 rows to understand the data schema and confirm the column to calculate the mean value\"}, {\"type\": \"send_to\", \"content\": \"CodeInterpreter\"}, {\"type\": \"message\", \"content\": \"Please load the data file [demo_data.csv](demo_data.csv) and show me the top 5 rows to understand the data schema\"}]}\n",
            "INFO:taskweaver.logging:Planner talk to CodeInterpreter: Please load the data file [demo_data.csv](demo_data.csv) and show me the top 5 rows to understand the data schema\n",
            "INFO:taskweaver.logging:LLM output: {\"response\": [{\"type\": \"thought\", \"content\": \"ProgramApe will generate a code snippet to load the data from 'demo_data.csv' and display the top 5 rows to understand the data schema.\"}, {\"type\": \"python\", \"content\": \"import pandas as pd\\n\\n# Load the data from demo_data.csv\\ndemo_data_df = pd.read_csv('demo_data.csv')\\n\\n# Display the top 5 rows to understand the data schema\\ntop_five_rows = demo_data_df.head()\\ntop_five_rows\"}]}\n",
            "INFO:taskweaver.logging:Code to be verified: import pandas as pd\n",
            "\n",
            "# Load the data from demo_data.csv\n",
            "demo_data_df = pd.read_csv('demo_data.csv')\n",
            "\n",
            "# Display the top 5 rows to understand the data schema\n",
            "top_five_rows = demo_data_df.head()\n",
            "top_five_rows\n",
            "INFO:taskweaver.logging:Code to be executed: import pandas as pd\n",
            "\n",
            "# Load the data from demo_data.csv\n",
            "demo_data_df = pd.read_csv('demo_data.csv')\n",
            "\n",
            "# Display the top 5 rows to understand the data schema\n",
            "top_five_rows = demo_data_df.head()\n",
            "top_five_rows\n",
            "ERROR:taskweaver.logging:Traceback (most recent call last):\n",
            "  File \"/content/TaskWeaver/taskweaver/session/session.py\", line 194, in _send_text_message\n",
            "    post = _send_message(post.send_to, post)\n",
            "  File \"/content/TaskWeaver/taskweaver/module/tracing.py\", line 174, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/content/TaskWeaver/taskweaver/session/session.py\", line 174, in _send_message\n",
            "    reply_post = self.worker_instances[recipient].reply(\n",
            "  File \"/content/TaskWeaver/taskweaver/module/tracing.py\", line 186, in wrapper\n",
            "    return func(self, *args, **kwargs)\n",
            "  File \"/content/TaskWeaver/taskweaver/code_interpreter/code_interpreter/code_interpreter.py\", line 234, in reply\n",
            "    exec_result = self.executor.execute_code(\n",
            "  File \"/content/TaskWeaver/taskweaver/module/tracing.py\", line 186, in wrapper\n",
            "    return func(self, *args, **kwargs)\n",
            "  File \"/content/TaskWeaver/taskweaver/code_interpreter/code_executor.py\", line 71, in execute_code\n",
            "    self.start()\n",
            "  File \"/content/TaskWeaver/taskweaver/code_interpreter/code_executor.py\", line 139, in start\n",
            "    self.exec_client.start()\n",
            "  File \"/content/TaskWeaver/taskweaver/ces/manager/sub_proc.py\", line 27, in start\n",
            "    self.mgr.env.start_session(self.session_id, session_dir=self.session_dir, cwd=self.cwd)\n",
            "  File \"/content/TaskWeaver/taskweaver/ces/environment.py\", line 223, in start_session\n",
            "    self._cmd_session_init(session)\n",
            "  File \"/content/TaskWeaver/taskweaver/ces/environment.py\", line 576, in _cmd_session_init\n",
            "    self._execute_control_code_on_kernel(\n",
            "  File \"/content/TaskWeaver/taskweaver/ces/environment.py\", line 463, in _execute_control_code_on_kernel\n",
            "    raise Exception(\"No text returned.\")\n",
            "Exception: No text returned.\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'id': 'round-20240418-003943-3c3c7b92', 'user_query': 'calculate the mean value of demo_data.csv', 'state': 'failed', 'post_list': [{'id': 'post-20240418-003943-68cc774f', 'message': 'calculate the mean value of demo_data.csv', 'send_from': 'User', 'send_to': 'Planner', 'attachment_list': []}, {'id': 'post-20240418-003943-917de349', 'message': 'Please load the data file [demo_data.csv](demo_data.csv) and show me the top 5 rows to understand the data schema', 'send_from': 'Planner', 'send_to': 'CodeInterpreter', 'attachment_list': [{'id': 'atta-20240418-003945-fdb75017', 'type': 'init_plan', 'content': '1. Load demo_data.csv and show me the top 5 rows to understand the data schema\\n2. Confirm the column to calculate the mean value <sequentially depends on 1>\\n3. Calculate the mean value of the specified column <interactively depends on 2>\\n4. Report the calculated mean value to the user <interactively depends on 3>', 'extra': None}, {'id': 'atta-20240418-003948-51f8cf5b', 'type': 'plan', 'content': '1. Load demo_data.csv and show me the top 5 rows to understand the data schema and confirm the column to calculate the mean value\\n2. Calculate the mean value of the specified column\\n3. Report the calculated mean value to the user', 'extra': None}, {'id': 'atta-20240418-003951-5ebf9c4f', 'type': 'current_plan_step', 'content': '1. Load demo_data.csv and show me the top 5 rows to understand the data schema and confirm the column to calculate the mean value', 'extra': None}, {'id': 'atta-20240418-003954-ce8c5247', 'type': 'board', 'content': 'I have drawn up a plan: \\n1. Load demo_data.csv and show me the top 5 rows to understand the data schema and confirm the column to calculate the mean value\\n2. Calculate the mean value of the specified column\\n3. Report the calculated mean value to the user\\n\\nPlease proceed with this step of this plan: Please load the data file [demo_data.csv](demo_data.csv) and show me the top 5 rows to understand the data schema', 'extra': None}]}]}\n"
          ]
        }
      ],
      "source": [
        "from taskweaver.app.app import TaskWeaverApp\n",
        "\n",
        "# This is the folder that contains the taskweaver_config.json file and not the repo root. Defaults to \"./project/\"\n",
        "app_dir = \"project/\"\n",
        "app = TaskWeaverApp(app_dir=app_dir)\n",
        "session = app.get_session()\n",
        "\n",
        "user_query = \"calculate the mean value of demo_data.csv\"\n",
        "response_round = session.send_message(user_query)\n",
        "print(response_round.to_dict())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AoIpeNvknrrS"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "fSuJQNDX-eD4",
        "fH3zCKA2t6vf",
        "r5JSicCauARv",
        "ZwsSagPXuHgM",
        "rS0H4IIx617-",
        "r1wi-T07vmpn"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
